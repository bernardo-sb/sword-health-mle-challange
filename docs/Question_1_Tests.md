# Question 1 - Testing Structure and Methodology

This document outlines the testing strategy used for validating the `transform_features_py` function. The test suite is built using `pytest`. It leverages parameterized tests and fixtures.

Tests are located in `tests/data_test.py`.

## Running Tests

To run the tests, you need to have dev dependencies installed (`make dev`). To run the tests, run:

```bash
pytest tests/data_test.py
```

## Test Data Preparation
Two key datasets are used in the tests:
- **`Expected Dataframe`**: The expected transformed dataset loaded from a pre-generated Parquet file (`features_expected.parquet`), which serves as a benchmark.
- **`Result Dataframe`**: The actual transformed dataset generated by running `transform_features_py()`.

## Fixtures
To avoid redundant computations and improve efficiency, two session-scoped fixtures are used:
- `expected_df`: Loads and preprocesses the expected dataset once per test session.
- `result_df`: Runs the transformation function once per test session and stores the result.
- `exercise_with_most_incorrect_df`: Loads the pre-generated Parquet file containing two columns, `exercise_with_most_incorrect_trans` (from the original dataset) and `exercise_with_most_incorrect_session` (from the original dataset).

Setting up a scope for the fixtures, via the `@pytest.fixture(scope="session")` decorator, ensures that the datasets are loaded and processed only once per test session, which increases tests speed.

Both datasets are reset to have sequential indexing and sorted based on the `session_group` column to maintain consistency in comparisons.

To make sure that the produced output was correct, the whole dataset is compared.

**Noticeable Anti-Pattern**: the tested function's result is used as a fixture, which is not  best practice (I've never seen it before). This is because the dataset is large enough that it would take too long to run the function for all tests. This way, the function is only run once per test session, significantly improving performance.

```python
@pytest.fixture(scope="session")
def result_df():
    df = transform_features_py().reset_index(drop=True).sort_values("session_group")
    return df
```

## Test Cases

### Column-Wise Equality Tests
Parameterized tests ensure that each specified column in the transformed dataset matches the expected values exactly. The following columns are checked: `session_group`, `patient_id`, `patient_name`, `patient_age`, `pain`, `fatigue`, `therapy_name`, `session_number`, `leave_session`, `quality`, `quality_reason_movement_detection`, `quality_reason_my_self_personal`, `quality_reason_other`, `quality_reason_exercises`, `quality_reason_tablet`, `quality_reason_tablet_and_or_motion_trackers`, `quality_reason_easy_of_use`, `quality_reason_session_speed`, `prescribed_repeats`, `training_time`, `number_exercises`, `number_of_distinct_exercises`.

The test function `test_transform_features_py_column` ensures that all values in these columns match using `numpy.testing.assert_array_equal`.

```python
@pytest.mark.parametrize("column",[
    "session_group",
    ...
    "number_of_distinct_exercises",
])
def test_transform_features_py_column(result_df, expected_df, column):
    assert_array_equal(result_df[column].values, expected_df[column].values)
```

### Floating Point Precision Test
Computational errors with floating points are mitigated by scaling the `perc_correct_repeats` column by 10,000 (to account for 2 decimal places) and converting it to an integer before comparison (`test_perc_correct_repeats`). This technique is common practice in financial computing.

```python
def test_perc_correct_repeats(result_df, expected_df):
    # computers don't like floats, so we multiply by 10,000 and convert to int
    # this will give us 2 decimal places precision
    assert_array_equal(
        (result_df["perc_correct_repeats"].values * 10000.0).astype(int),
        (expected_df["perc_correct_repeats"].values * 10000.0).astype(int))
``` 

### Validating `session_is_nok` - Handling Missing Values
The `session_is_nok` column may contain missing values. The test `test_session_is_nok` replaces NaN values with `-1` before asserting equality, thus treating the boolean column as an integer. This is to prevent `assert_array_equal` from failing due to missing values.

```python
def test_session_is_nok(result_df, expected_df):
    assert_array_equal(
        result_df["session_is_nok"].fillna(-1).values,
        expected_df["session_is_nok"].fillna(-1).values
    )
```

### Leave Exercise Validation

The `leave_exercise_*` columns are treated as integers to facilitate comparison.

```python
@pytest.mark.parametrize("column",[
    "leave_exercise_system_problem",
    ...
    "leave_exercise_difficulty",
])
def test_leave_exercise(result_df, expected_df, column):
    assert_array_equal(
        result_df[column].values.astype(int),
        expected_df[column].values.astype(int)
    )
```

### String Column Handling
Columns containing string values, such as `first_exercise_skipped`, are compared after filling missing values with a placeholder (`-`).

```python
def test_identify_first_exercise_skipped(result_df, expected_df):
    assert_array_equal(
        result_df["first_exercise_skipped"].fillna("-").values,
        expected_df["first_exercise_skipped"].fillna("-").values
    )
```

### Matching for Ambiguous Cases
For `exercise_with_most_incorrect`, an exact match is not required since multiple exercises may share the same number of incorrect attempts. Instead, the test asserts that at least one of the columns matches.

```python
def test_identify_most_incorrect_exercise(result_df, exercise_with_most_incorrect_df):
    # mast match a least one
    trans_col = result_df["exercise_with_most_incorrect"].fillna("-").values ==\
    exercise_with_most_incorrect_df["exercise_with_most_incorrect_trans"].fillna("-").values
    
    session_col = result_df["exercise_with_most_incorrect"].fillna("-").values ==\
    exercise_with_most_incorrect_df["exercise_with_most_incorrect_session"].fillna("-").values

    assert np.all((trans_col + session_col) > 0)
```

## Conclusion and Considerations

The test suite verifies the correctness of the `transform_features_py` function by comparing the result with the expected values. It uses parameterized tests and fixtures to handle the data and assertions. It breaks down the tests into smaller, focused tests, to address specific cases.

In addition, all functions constituting the `transform_features_py` function should also be tested, to ensure that they work correctly and that the output is as expected.
