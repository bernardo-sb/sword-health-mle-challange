{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"SWORD Health MLE Challenge - Bernardo de Lemos","text":"<p>This document summarizes the process I followed to complete the challenge.</p> <p>Solutions are provided as code. Details and explanations are provided in the <code>docs</code> directory.</p>"},{"location":"#index","title":"Index","text":"<ul> <li>Question 1: Step-by-step transformation walkthrough in a Jupyter Notebook.</li> <li>Question 1 - Testing Structure and Methodology: Testing structure and methodology.</li> <li>Question 2a: Solution and explanation.</li> <li>Question 2b: Solution and explanation.</li> </ul>"},{"location":"#process-overview","title":"Process Overview","text":"<p>Initial Setup - Started by reading the <code>README.md</code> file to understand the instructions and project structure. - Unzipped and inspected the data files in the <code>data</code> directory (parquet viewer and Jupyter notebook).</p> <p>Environment Configuration - Encountered version conflicts due to Python 3.13 on my local machine. - Resolved the issue by modifying the <code>Makefile</code> to use Python 3.11. - Used <code>uv</code> as the package manager. - Created a <code>dev</code> extra in <code>setup.py</code>.     - Added <code>pytest</code> to <code>dev</code>.     - Added <code>mkdocs</code>, <code>mkdocs-material</code>, <code>mkdocs-jupyter</code>, and <code>mkdocstrings[python]</code> to <code>dev</code>. - Created a <code>dev</code> target in the <code>Makefile</code> for development setup. - Added a <code>get-message</code> command in the <code>Makefile</code> to run with a session group parameter.</p>"},{"location":"#installation-guide","title":"Installation Guide","text":""},{"location":"#installing-uv","title":"Installing <code>uv</code>","text":"<p>Follow the instructions in the uv repository to install <code>uv</code>.</p>"},{"location":"#makefile-modifications","title":"Makefile Modifications","text":"<pre><code>@@ -2,12 +2,20 @@\n\n .ONESHELL:\n venv:\n-   python3 -m venv venv\n-   source venv/bin/activate &amp;&amp; \\\n-   python -m pip install --upgrade pip setuptools wheel pipenv &amp;&amp; \\\n-   python -m pip install -e .\n+   uv venv --python 3.11\n+   uv pip install --upgrade pip setuptools wheel pipenv\n+   uv pip install -e .\n+\n+.PHONY: dev\n+dev:\n+   uv venv --python 3.11\n+   uv pip install --upgrade pip setuptools wheel pipenv\n+   uv pip install -e .[dev]\n\n-# transform\n .PHONY: transform\n transform:\n-   message transform\n\\ No newline at end of file\n+   message transform\n+\n+.PHONY: get-message\n+get-message:\n+   message get-message $(session_group)\n</code></pre>"},{"location":"#setuppy-modifications","title":"<code>setup.py</code> Modifications","text":"<pre><code>@@ -12,6 +12,16 @@ packages = [\n     \"pyarrow==14.0.2\",\n     \"SQLAlchemy==1.4.46\",\n     \"typer==0.9.0\",\n+    \"pyyaml\"\n+]\n+\n+dev_packages = [\n+    \"pytest\",\n+    \"mkdocs\",\n+    \"mkdocs-material\",\n+    \"mkdocs-jupyter\",\n+    \"mkdocstrings[python]\",\n+    *packages,\n ]\n\n setup(\n@@ -19,7 +29,7 @@ setup(\n     version=\"0.1.0\",\n     author=\"Sword Health\",\n     author_email=\"ai@swordhealth.com\",\n-    python_requires=\"&gt;=3.8\",\n+    python_requires=\"&gt;=3.8, &lt;=3.11\",\n     packages=find_packages(exclude=(\"tests\", \"resources\")),\n     install_requires=packages,\n     entry_points={\n@@ -27,4 +37,7 @@ setup(\n             \"message = message.main:app\",\n         ],\n     },\n+    extras_require={\n+        \"dev\": dev_packages,\n+    },\n )\n</code></pre>"},{"location":"#documentation","title":"Documentation","text":"<p>Documentation is powered by mkdocs. Configuration is in mkdocs.yml.</p> <p>You can either read the documentation on your browser (using built docs) or read it on your IDE directly from files.</p>"},{"location":"#building-documentation","title":"Building Documentation","text":"<p>To build the documentation you need to have dev dependencies installed (<code>make dev</code>). To build to target directory (<code>docs_build</code>), run:</p> <pre><code>mkdocs build -d docs_build\n</code></pre>"},{"location":"#opening-built-documentation","title":"Opening Built Documentation","text":"<p>To open the built documentation you must open the <code>docs_build/index.html</code> file on your browser.</p> <p>On mac:</p> <pre><code>open docs_build/index.html\n</code></pre>"},{"location":"#serving-documentation","title":"Serving Documentation","text":"<p>To serve the documentation on local host, run:</p> <pre><code>mkdocs serve\n</code></pre>"},{"location":"Question_1/","title":"Question 1","text":"In\u00a0[1]: Copied! <pre>import pandas as pd\nfrom pathlib import Path\n\nfrom message.config import DATA_DIR # no it module\n\ndef load_exercise_data(data_dir: str | Path) -&gt; pd.DataFrame:\n    \"\"\"Load exercise results data from parquet file.\n    \n    Parameters\n    ----------\n    data_dir : str or Path\n        Directory containing the exercise results data.\n        \n    Returns\n    -------\n    pd.DataFrame\n        Raw exercise results data.\n    \"\"\"\n    return pd.read_parquet(Path(data_dir, \"exercise_results.parquet\"))\n\n\ndf = load_exercise_data(DATA_DIR)\ndf\n</pre>  import pandas as pd from pathlib import Path  from message.config import DATA_DIR # no it module  def load_exercise_data(data_dir: str | Path) -&gt; pd.DataFrame:     \"\"\"Load exercise results data from parquet file.          Parameters     ----------     data_dir : str or Path         Directory containing the exercise results data.              Returns     -------     pd.DataFrame         Raw exercise results data.     \"\"\"     return pd.read_parquet(Path(data_dir, \"exercise_results.parquet\"))   df = load_exercise_data(DATA_DIR) df Out[1]: session_exercise_result_sword_id session_group patient_id therapy_name exercise_name exercise_side exercise_order prescribed_repeats training_time correct_repeats ... quality_reason_other quality_reason_exercises quality_reason_tablet_and_or_motion_trackers quality_reason_easy_of_use quality_reason_tablet quality_reason_session_speed session_number session_is_nok patient_name patient_age 0 39810278 lg1c88p/9QtkOmQwiwd5stMlmOU= glRS/3uRDZt6RpmB+LaLyx/a7wk= low_back prone_press_ups center 10 5 35 1 ... 0 0 0 0 0 0 318 False Sonya Berg 76 1 39810303 lg1c88p/9QtkOmQwiwd5stMlmOU= glRS/3uRDZt6RpmB+LaLyx/a7wk= low_back child's_pose center 12 1 33 1 ... 0 0 0 0 0 0 318 False Sonya Berg 76 2 39810255 lg1c88p/9QtkOmQwiwd5stMlmOU= glRS/3uRDZt6RpmB+LaLyx/a7wk= low_back plank center 7 3 36 1 ... 0 0 0 0 0 0 318 False Sonya Berg 76 3 39810227 lg1c88p/9QtkOmQwiwd5stMlmOU= glRS/3uRDZt6RpmB+LaLyx/a7wk= low_back pelvic_anterior_posterior_tilt center 4 20 23 20 ... 0 0 0 0 0 0 318 False Sonya Berg 76 4 39810238 lg1c88p/9QtkOmQwiwd5stMlmOU= glRS/3uRDZt6RpmB+LaLyx/a7wk= low_back pelvic_side_tilt center 5 20 24 20 ... 0 0 0 0 0 0 318 False Sonya Berg 76 ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... 1126649 40189500 BvM0aISy9U19fgHIIliUzbJ3B9M= N2dimTApy2aibVhQf3sKNqv+XQ8= low_back squat bilateral 6 8 29 6 ... 0 0 0 0 0 0 1 False Nicole Acevedo 69 1126650 40189427 BvM0aISy9U19fgHIIliUzbJ3B9M= N2dimTApy2aibVhQf3sKNqv+XQ8= low_back side_step bilateral 5 8 23 8 ... 0 0 0 0 0 0 1 False Nicole Acevedo 69 1126651 40190119 BvM0aISy9U19fgHIIliUzbJ3B9M= N2dimTApy2aibVhQf3sKNqv+XQ8= low_back side_lying_clamshells right 8 8 98 8 ... 0 0 0 0 0 0 1 False Nicole Acevedo 69 1126652 40190002 BvM0aISy9U19fgHIIliUzbJ3B9M= N2dimTApy2aibVhQf3sKNqv+XQ8= low_back side_lying_clamshells left 7 8 263 8 ... 0 0 0 0 0 0 1 False Nicole Acevedo 69 1126653 40189354 BvM0aISy9U19fgHIIliUzbJ3B9M= N2dimTApy2aibVhQf3sKNqv+XQ8= low_back squat bilateral 3 8 33 8 ... 0 0 0 0 0 0 1 False Nicole Acevedo 69 <p>1126654 rows \u00d7 28 columns</p> In\u00a0[2]: Copied! <pre>def aggregate_session_data(df: pd.DataFrame) -&gt; pd.DataFrame:\n    \"\"\"Aggregate exercise data by session group.\n    \n    Parameters\n    ----------\n    df : pd.DataFrame\n        Raw exercise results data.\n        \n    Returns\n    -------\n    pd.DataFrame\n        Data aggregated by session_group.\n    \"\"\"\n    grouped = df.groupby(\"session_group\").agg(\n        patient_id=(\"patient_id\", \"first\"),\n        patient_name=(\"patient_name\", \"first\"),\n        patient_age=(\"patient_age\", \"first\"),\n        pain=(\"pain\", \"first\"),\n        fatigue=(\"fatigue\", \"first\"),\n        therapy_name=(\"therapy_name\", \"first\"),\n        session_number=(\"session_number\", \"first\"),\n        leave_session=(\"leave_session\", \"first\"),\n        quality=(\"quality\", \"first\"),\n        session_is_nok=(\"session_is_nok\", \"first\"),\n        prescribed_repeats=(\"prescribed_repeats\", \"sum\"),\n        training_time=(\"training_time\", \"sum\"),\n        correct_repeats=(\"correct_repeats\", \"sum\"),\n        wrong_repeats=(\"wrong_repeats\", \"sum\"),\n        number_exercises=(\"exercise_name\", \"count\"),\n        number_of_distinct_exercises=(\"exercise_name\", \"nunique\"),\n        quality_reason_movement_detection=(\"quality_reason_movement_detection\", \"first\"),\n        quality_reason_my_self_personal=(\"quality_reason_my_self_personal\", \"first\"),\n        quality_reason_other=(\"quality_reason_other\", \"first\"),\n        quality_reason_exercises=(\"quality_reason_exercises\", \"first\"),\n        quality_reason_tablet=(\"quality_reason_tablet\", \"first\"),\n        quality_reason_tablet_and_or_motion_trackers=(\"quality_reason_tablet_and_or_motion_trackers\", \"first\"),\n        quality_reason_easy_of_use=(\"quality_reason_easy_of_use\", \"first\"),\n        quality_reason_session_speed=(\"quality_reason_session_speed\", \"first\"),\n    ).reset_index()\n    \n    grouped[\"session_is_nok\"] = grouped[\"session_is_nok\"].astype(\"object\")\n    grouped[\"pain\"] = grouped[\"pain\"].astype(\"float64\")\n    grouped[\"fatigue\"] = grouped[\"fatigue\"].astype(\"float64\")\n    grouped[\"session_number\"] = grouped[\"session_number\"].astype(\"int64\")\n    grouped[\"quality\"] = grouped[\"quality\"].astype(\"float64\")\n    grouped[\"quality_reason_movement_detection\"] = grouped[\"quality_reason_movement_detection\"].astype(\"int64\")\n    grouped[\"quality_reason_my_self_personal\"] = grouped[\"quality_reason_my_self_personal\"].astype(\"int64\")\n    grouped[\"quality_reason_other\"] = grouped[\"quality_reason_other\"].astype(\"int64\")\n    grouped[\"quality_reason_exercises\"] = grouped[\"quality_reason_exercises\"].astype(\"int64\")\n    grouped[\"quality_reason_tablet\"] = grouped[\"quality_reason_tablet\"].astype(\"int64\")\n    grouped[\"quality_reason_tablet_and_or_motion_trackers\"] = grouped[\"quality_reason_tablet_and_or_motion_trackers\"].astype(\"int64\")\n    grouped[\"quality_reason_easy_of_use\"] = grouped[\"quality_reason_easy_of_use\"].astype(\"int64\")\n    grouped[\"quality_reason_session_speed\"] = grouped[\"quality_reason_session_speed\"].astype(\"int64\")\n\n    return grouped\n\ndf_step_2 = aggregate_session_data(df)\ndf_step_2\n</pre> def aggregate_session_data(df: pd.DataFrame) -&gt; pd.DataFrame:     \"\"\"Aggregate exercise data by session group.          Parameters     ----------     df : pd.DataFrame         Raw exercise results data.              Returns     -------     pd.DataFrame         Data aggregated by session_group.     \"\"\"     grouped = df.groupby(\"session_group\").agg(         patient_id=(\"patient_id\", \"first\"),         patient_name=(\"patient_name\", \"first\"),         patient_age=(\"patient_age\", \"first\"),         pain=(\"pain\", \"first\"),         fatigue=(\"fatigue\", \"first\"),         therapy_name=(\"therapy_name\", \"first\"),         session_number=(\"session_number\", \"first\"),         leave_session=(\"leave_session\", \"first\"),         quality=(\"quality\", \"first\"),         session_is_nok=(\"session_is_nok\", \"first\"),         prescribed_repeats=(\"prescribed_repeats\", \"sum\"),         training_time=(\"training_time\", \"sum\"),         correct_repeats=(\"correct_repeats\", \"sum\"),         wrong_repeats=(\"wrong_repeats\", \"sum\"),         number_exercises=(\"exercise_name\", \"count\"),         number_of_distinct_exercises=(\"exercise_name\", \"nunique\"),         quality_reason_movement_detection=(\"quality_reason_movement_detection\", \"first\"),         quality_reason_my_self_personal=(\"quality_reason_my_self_personal\", \"first\"),         quality_reason_other=(\"quality_reason_other\", \"first\"),         quality_reason_exercises=(\"quality_reason_exercises\", \"first\"),         quality_reason_tablet=(\"quality_reason_tablet\", \"first\"),         quality_reason_tablet_and_or_motion_trackers=(\"quality_reason_tablet_and_or_motion_trackers\", \"first\"),         quality_reason_easy_of_use=(\"quality_reason_easy_of_use\", \"first\"),         quality_reason_session_speed=(\"quality_reason_session_speed\", \"first\"),     ).reset_index()          grouped[\"session_is_nok\"] = grouped[\"session_is_nok\"].astype(\"object\")     grouped[\"pain\"] = grouped[\"pain\"].astype(\"float64\")     grouped[\"fatigue\"] = grouped[\"fatigue\"].astype(\"float64\")     grouped[\"session_number\"] = grouped[\"session_number\"].astype(\"int64\")     grouped[\"quality\"] = grouped[\"quality\"].astype(\"float64\")     grouped[\"quality_reason_movement_detection\"] = grouped[\"quality_reason_movement_detection\"].astype(\"int64\")     grouped[\"quality_reason_my_self_personal\"] = grouped[\"quality_reason_my_self_personal\"].astype(\"int64\")     grouped[\"quality_reason_other\"] = grouped[\"quality_reason_other\"].astype(\"int64\")     grouped[\"quality_reason_exercises\"] = grouped[\"quality_reason_exercises\"].astype(\"int64\")     grouped[\"quality_reason_tablet\"] = grouped[\"quality_reason_tablet\"].astype(\"int64\")     grouped[\"quality_reason_tablet_and_or_motion_trackers\"] = grouped[\"quality_reason_tablet_and_or_motion_trackers\"].astype(\"int64\")     grouped[\"quality_reason_easy_of_use\"] = grouped[\"quality_reason_easy_of_use\"].astype(\"int64\")     grouped[\"quality_reason_session_speed\"] = grouped[\"quality_reason_session_speed\"].astype(\"int64\")      return grouped  df_step_2 = aggregate_session_data(df) df_step_2 Out[2]: session_group patient_id patient_name patient_age pain fatigue therapy_name session_number leave_session quality ... number_exercises number_of_distinct_exercises quality_reason_movement_detection quality_reason_my_self_personal quality_reason_other quality_reason_exercises quality_reason_tablet quality_reason_tablet_and_or_motion_trackers quality_reason_easy_of_use quality_reason_session_speed 0 ++//wixk6DpH8NMGvqLqvpzWbzY= 3FDm7kzjNVgmqUPhyODoZpMIIGc= Taylor Mendez 55 6.0 4.0 shoulder 6 None 4.0 ... 8 8 0 0 1 1 0 0 1 1 1 ++2JgoMe8JGBtUHdsOiLGO8UZ18= KRnwvSlSa6U62Edl3dHJa0nVM5A= Danielle Miller 75 4.0 0.0 knee 8 None 5.0 ... 19 10 0 0 0 0 0 0 0 0 2 ++4kUzy7ewH5u7FjNoU8CW6thbY= euuPYQwygUQC94V0LvmFOzHPoXQ= Jeremy Randall 70 4.0 2.0 low_back 9 None 5.0 ... 18 12 0 0 0 0 0 0 0 0 3 ++8Q+lFKrp9IKCWsBT0IO0XEV1Y= R0S8jUhp1lC00zuUYuB0QAnj6as= Richard Robinson 98 4.0 4.0 low_back 2 None 4.0 ... 7 7 0 1 0 0 0 0 0 0 4 ++9PC4/46Jmrl/PHbzkM1BCPg2g= Uj48yKb4R53oteHJHRcnzpUjBdY= Hector Perry 28 2.0 2.0 knee 17 None 5.0 ... 16 11 0 0 0 0 0 0 0 0 ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... 74785 zzjYItanfFoaxcOT72WuLVdFlpU= p5r85M4UOxA+ooLsAnpGA091yec= Brianna George 28 2.0 0.0 shoulder 11 None 5.0 ... 23 12 0 0 0 0 0 0 0 0 74786 zzkMg0F+Nr92E2UwQld7T2c9DxY= Q8xrPkPRSOYhbjrzTxF77Fp40IA= Sophia Harris 85 8.0 4.0 neck 13 None 5.0 ... 18 11 0 0 0 0 0 0 0 0 74787 zzwyhOME0/jCt/TlocGDlnM7Nx4= 4tqtZxzLS9+7QJtKa3pW0beUG3s= Donna Moreno 34 0.0 0.0 elbow 13 None 5.0 ... 18 8 0 0 0 0 0 0 0 0 74788 zzy4uJWf1oWcSbMEHF4RG15ELcU= bWap/fmf6koGTRDMpejv7/J+ovw= Nancy Walter 96 4.0 0.0 low_back 1 None 3.0 ... 13 7 1 0 0 0 0 0 0 0 74789 zzywE42oNH4kWtcuDUxFj4IHFE4= naNdxtOYuAu+68EE17RaSQ8j2PM= Michael Greer DDS 32 6.0 6.0 shoulder 3 None 5.0 ... 10 8 0 0 0 0 0 0 0 0 <p>74790 rows \u00d7 25 columns</p> In\u00a0[3]: Copied! <pre>def calculate_performance_metrics(grouped: pd.DataFrame) -&gt; pd.DataFrame:\n    \"\"\"Calculate performance metrics for each session.\n    \n    Parameters\n    ----------\n    grouped : pd.DataFrame\n        Aggregated session data.\n        \n    Returns\n    -------\n    pd.DataFrame\n        Session data with performance metrics added.\n    \"\"\"\n    grouped[\"perc_correct_repeats\"] = grouped[\"correct_repeats\"] / (grouped[\"correct_repeats\"] + grouped[\"wrong_repeats\"])\n    return grouped\n\ndf_step_3 = calculate_performance_metrics(df_step_2)\ndf_step_3\n</pre> def calculate_performance_metrics(grouped: pd.DataFrame) -&gt; pd.DataFrame:     \"\"\"Calculate performance metrics for each session.          Parameters     ----------     grouped : pd.DataFrame         Aggregated session data.              Returns     -------     pd.DataFrame         Session data with performance metrics added.     \"\"\"     grouped[\"perc_correct_repeats\"] = grouped[\"correct_repeats\"] / (grouped[\"correct_repeats\"] + grouped[\"wrong_repeats\"])     return grouped  df_step_3 = calculate_performance_metrics(df_step_2) df_step_3 Out[3]: session_group patient_id patient_name patient_age pain fatigue therapy_name session_number leave_session quality ... number_of_distinct_exercises quality_reason_movement_detection quality_reason_my_self_personal quality_reason_other quality_reason_exercises quality_reason_tablet quality_reason_tablet_and_or_motion_trackers quality_reason_easy_of_use quality_reason_session_speed perc_correct_repeats 0 ++//wixk6DpH8NMGvqLqvpzWbzY= 3FDm7kzjNVgmqUPhyODoZpMIIGc= Taylor Mendez 55 6.0 4.0 shoulder 6 None 4.0 ... 8 0 0 1 1 0 0 1 1 0.989583 1 ++2JgoMe8JGBtUHdsOiLGO8UZ18= KRnwvSlSa6U62Edl3dHJa0nVM5A= Danielle Miller 75 4.0 0.0 knee 8 None 5.0 ... 10 0 0 0 0 0 0 0 0 0.995 2 ++4kUzy7ewH5u7FjNoU8CW6thbY= euuPYQwygUQC94V0LvmFOzHPoXQ= Jeremy Randall 70 4.0 2.0 low_back 9 None 5.0 ... 12 0 0 0 0 0 0 0 0 0.993333 3 ++8Q+lFKrp9IKCWsBT0IO0XEV1Y= R0S8jUhp1lC00zuUYuB0QAnj6as= Richard Robinson 98 4.0 4.0 low_back 2 None 4.0 ... 7 0 1 0 0 0 0 0 0 0.88 4 ++9PC4/46Jmrl/PHbzkM1BCPg2g= Uj48yKb4R53oteHJHRcnzpUjBdY= Hector Perry 28 2.0 2.0 knee 17 None 5.0 ... 11 0 0 0 0 0 0 0 0 0.986395 ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... 74785 zzjYItanfFoaxcOT72WuLVdFlpU= p5r85M4UOxA+ooLsAnpGA091yec= Brianna George 28 2.0 0.0 shoulder 11 None 5.0 ... 12 0 0 0 0 0 0 0 0 0.968182 74786 zzkMg0F+Nr92E2UwQld7T2c9DxY= Q8xrPkPRSOYhbjrzTxF77Fp40IA= Sophia Harris 85 8.0 4.0 neck 13 None 5.0 ... 11 0 0 0 0 0 0 0 0 0.992958 74787 zzwyhOME0/jCt/TlocGDlnM7Nx4= 4tqtZxzLS9+7QJtKa3pW0beUG3s= Donna Moreno 34 0.0 0.0 elbow 13 None 5.0 ... 8 0 0 0 0 0 0 0 0 0.990741 74788 zzy4uJWf1oWcSbMEHF4RG15ELcU= bWap/fmf6koGTRDMpejv7/J+ovw= Nancy Walter 96 4.0 0.0 low_back 1 None 3.0 ... 7 1 0 0 0 0 0 0 0 0.949153 74789 zzywE42oNH4kWtcuDUxFj4IHFE4= naNdxtOYuAu+68EE17RaSQ8j2PM= Michael Greer DDS 32 6.0 6.0 shoulder 3 None 5.0 ... 8 0 0 0 0 0 0 0 0 0.991228 <p>74790 rows \u00d7 26 columns</p> In\u00a0[4]: Copied! <pre>def add_reason_counts(df: pd.DataFrame, grouped: pd.DataFrame) -&gt; pd.DataFrame:\n    \"\"\"Add counts for different reasons for leaving exercises.\n    \n    Parameters\n    ----------\n    df : pd.DataFrame\n        Raw exercise results data.\n    grouped : pd.DataFrame\n        Aggregated session data.\n        \n    Returns\n    -------\n    pd.DataFrame\n        Session data with reason counts added.\n    \"\"\"\n    leave_exercise_reasons = [\"system_problem\", \"other\", \"unable_perform\", \"pain\", \"tired\", \"technical_issues\", \"difficulty\"]\n\n    df.set_index(\"session_group\", inplace=True)\n    grouped.set_index(\"session_group\", inplace=True)\n\n    for reason in leave_exercise_reasons:\n        grouped[f\"leave_exercise_{reason}\"] = 0\n        df_leave_exercise = df[df[\"leave_exercise\"] == reason].groupby(\"session_group\")[\"leave_exercise\"].count()\n        grouped.loc[df_leave_exercise.index, f\"leave_exercise_{reason}\"] = df_leave_exercise.values\n        grouped[f\"leave_exercise_{reason}\"].fillna(0, inplace=True)\n    \n    grouped.reset_index(inplace=True) # this is inneficient...\n    return grouped\n\ndf_step_4 = add_reason_counts(df, df_step_3)\ndf_step_4\n</pre> def add_reason_counts(df: pd.DataFrame, grouped: pd.DataFrame) -&gt; pd.DataFrame:     \"\"\"Add counts for different reasons for leaving exercises.          Parameters     ----------     df : pd.DataFrame         Raw exercise results data.     grouped : pd.DataFrame         Aggregated session data.              Returns     -------     pd.DataFrame         Session data with reason counts added.     \"\"\"     leave_exercise_reasons = [\"system_problem\", \"other\", \"unable_perform\", \"pain\", \"tired\", \"technical_issues\", \"difficulty\"]      df.set_index(\"session_group\", inplace=True)     grouped.set_index(\"session_group\", inplace=True)      for reason in leave_exercise_reasons:         grouped[f\"leave_exercise_{reason}\"] = 0         df_leave_exercise = df[df[\"leave_exercise\"] == reason].groupby(\"session_group\")[\"leave_exercise\"].count()         grouped.loc[df_leave_exercise.index, f\"leave_exercise_{reason}\"] = df_leave_exercise.values         grouped[f\"leave_exercise_{reason}\"].fillna(0, inplace=True)          grouped.reset_index(inplace=True) # this is inneficient...     return grouped  df_step_4 = add_reason_counts(df, df_step_3) df_step_4 Out[4]: session_group patient_id patient_name patient_age pain fatigue therapy_name session_number leave_session quality ... quality_reason_easy_of_use quality_reason_session_speed perc_correct_repeats leave_exercise_system_problem leave_exercise_other leave_exercise_unable_perform leave_exercise_pain leave_exercise_tired leave_exercise_technical_issues leave_exercise_difficulty 0 ++//wixk6DpH8NMGvqLqvpzWbzY= 3FDm7kzjNVgmqUPhyODoZpMIIGc= Taylor Mendez 55 6.0 4.0 shoulder 6 None 4.0 ... 1 1 0.989583 0 0 0 0 0 0 0 1 ++2JgoMe8JGBtUHdsOiLGO8UZ18= KRnwvSlSa6U62Edl3dHJa0nVM5A= Danielle Miller 75 4.0 0.0 knee 8 None 5.0 ... 0 0 0.995 0 0 0 0 0 0 0 2 ++4kUzy7ewH5u7FjNoU8CW6thbY= euuPYQwygUQC94V0LvmFOzHPoXQ= Jeremy Randall 70 4.0 2.0 low_back 9 None 5.0 ... 0 0 0.993333 0 0 0 0 0 0 0 3 ++8Q+lFKrp9IKCWsBT0IO0XEV1Y= R0S8jUhp1lC00zuUYuB0QAnj6as= Richard Robinson 98 4.0 4.0 low_back 2 None 4.0 ... 0 0 0.88 0 0 0 0 0 0 0 4 ++9PC4/46Jmrl/PHbzkM1BCPg2g= Uj48yKb4R53oteHJHRcnzpUjBdY= Hector Perry 28 2.0 2.0 knee 17 None 5.0 ... 0 0 0.986395 0 0 0 0 0 0 0 ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... 74785 zzjYItanfFoaxcOT72WuLVdFlpU= p5r85M4UOxA+ooLsAnpGA091yec= Brianna George 28 2.0 0.0 shoulder 11 None 5.0 ... 0 0 0.968182 0 0 0 0 0 0 0 74786 zzkMg0F+Nr92E2UwQld7T2c9DxY= Q8xrPkPRSOYhbjrzTxF77Fp40IA= Sophia Harris 85 8.0 4.0 neck 13 None 5.0 ... 0 0 0.992958 0 0 0 0 0 0 0 74787 zzwyhOME0/jCt/TlocGDlnM7Nx4= 4tqtZxzLS9+7QJtKa3pW0beUG3s= Donna Moreno 34 0.0 0.0 elbow 13 None 5.0 ... 0 0 0.990741 0 0 0 0 0 0 0 74788 zzy4uJWf1oWcSbMEHF4RG15ELcU= bWap/fmf6koGTRDMpejv7/J+ovw= Nancy Walter 96 4.0 0.0 low_back 1 None 3.0 ... 0 0 0.949153 0 0 0 0 0 0 0 74789 zzywE42oNH4kWtcuDUxFj4IHFE4= naNdxtOYuAu+68EE17RaSQ8j2PM= Michael Greer DDS 32 6.0 6.0 shoulder 3 None 5.0 ... 0 0 0.991228 0 0 0 0 0 0 0 <p>74790 rows \u00d7 33 columns</p> In\u00a0[5]: Copied! <pre>def identify_most_incorrect_exercise(df: pd.DataFrame, grouped: pd.DataFrame) -&gt; pd.DataFrame:\n    \"\"\"Identify exercises with most incorrect.\n    \n    Parameters\n    ----------\n    df : pd.DataFrame\n        Raw exercise results data.\n    grouped : pd.DataFrame\n        Aggregated session data.\n        \n    Returns\n    -------\n    pd.DataFrame\n        Session data with problematic exercise information added.\n    \"\"\"\n\n    grouped_wrong_reps = df.groupby([\"session_group\", \"exercise_name\"])[\"wrong_repeats\"].sum().reset_index()\n    grouped_incorrect_ex = grouped_wrong_reps.loc[grouped_wrong_reps.groupby(\"session_group\")[\"wrong_repeats\"].idxmax()].drop(columns=\"wrong_repeats\", axis=1)\n    grouped = grouped.merge(grouped_incorrect_ex, on=\"session_group\", how=\"left\")\n    grouped = grouped.rename(columns={\"exercise_name\": \"exercise_with_most_incorrect\"})\n    \n    return grouped\n    \ndf_step_5 = identify_most_incorrect_exercise(df, df_step_4)\ndf_step_5\n</pre> def identify_most_incorrect_exercise(df: pd.DataFrame, grouped: pd.DataFrame) -&gt; pd.DataFrame:     \"\"\"Identify exercises with most incorrect.          Parameters     ----------     df : pd.DataFrame         Raw exercise results data.     grouped : pd.DataFrame         Aggregated session data.              Returns     -------     pd.DataFrame         Session data with problematic exercise information added.     \"\"\"      grouped_wrong_reps = df.groupby([\"session_group\", \"exercise_name\"])[\"wrong_repeats\"].sum().reset_index()     grouped_incorrect_ex = grouped_wrong_reps.loc[grouped_wrong_reps.groupby(\"session_group\")[\"wrong_repeats\"].idxmax()].drop(columns=\"wrong_repeats\", axis=1)     grouped = grouped.merge(grouped_incorrect_ex, on=\"session_group\", how=\"left\")     grouped = grouped.rename(columns={\"exercise_name\": \"exercise_with_most_incorrect\"})          return grouped      df_step_5 = identify_most_incorrect_exercise(df, df_step_4) df_step_5 Out[5]: session_group patient_id patient_name patient_age pain fatigue therapy_name session_number leave_session quality ... quality_reason_session_speed perc_correct_repeats leave_exercise_system_problem leave_exercise_other leave_exercise_unable_perform leave_exercise_pain leave_exercise_tired leave_exercise_technical_issues leave_exercise_difficulty exercise_with_most_incorrect 0 ++//wixk6DpH8NMGvqLqvpzWbzY= 3FDm7kzjNVgmqUPhyODoZpMIIGc= Taylor Mendez 55 6.0 4.0 shoulder 6 None 4.0 ... 1 0.989583 0 0 0 0 0 0 0 shoulder_abduction 1 ++2JgoMe8JGBtUHdsOiLGO8UZ18= KRnwvSlSa6U62Edl3dHJa0nVM5A= Danielle Miller 75 4.0 0.0 knee 8 None 5.0 ... 0 0.995 0 0 0 0 0 0 0 hip_abduction 2 ++4kUzy7ewH5u7FjNoU8CW6thbY= euuPYQwygUQC94V0LvmFOzHPoXQ= Jeremy Randall 70 4.0 2.0 low_back 9 None 5.0 ... 0 0.993333 0 0 0 0 0 0 0 hip_hyperextension 3 ++8Q+lFKrp9IKCWsBT0IO0XEV1Y= R0S8jUhp1lC00zuUYuB0QAnj6as= Richard Robinson 98 4.0 4.0 low_back 2 None 4.0 ... 0 0.88 0 0 0 0 0 0 0 knee_flexion 4 ++9PC4/46Jmrl/PHbzkM1BCPg2g= Uj48yKb4R53oteHJHRcnzpUjBdY= Hector Perry 28 2.0 2.0 knee 17 None 5.0 ... 0 0.986395 0 0 0 0 0 0 0 airplane ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... 74785 zzjYItanfFoaxcOT72WuLVdFlpU= p5r85M4UOxA+ooLsAnpGA091yec= Brianna George 28 2.0 0.0 shoulder 11 None 5.0 ... 0 0.968182 0 0 0 0 0 0 0 diagonal_1_flexion 74786 zzkMg0F+Nr92E2UwQld7T2c9DxY= Q8xrPkPRSOYhbjrzTxF77Fp40IA= Sophia Harris 85 8.0 4.0 neck 13 None 5.0 ... 0 0.992958 0 0 0 0 0 0 0 sitting_neck_side_bending 74787 zzwyhOME0/jCt/TlocGDlnM7Nx4= 4tqtZxzLS9+7QJtKa3pW0beUG3s= Donna Moreno 34 0.0 0.0 elbow 13 None 5.0 ... 0 0.990741 0 0 0 0 0 0 0 diagonal_1_flexion 74788 zzy4uJWf1oWcSbMEHF4RG15ELcU= bWap/fmf6koGTRDMpejv7/J+ovw= Nancy Walter 96 4.0 0.0 low_back 1 None 3.0 ... 0 0.949153 0 0 0 0 0 0 0 hip_hyperextension 74789 zzywE42oNH4kWtcuDUxFj4IHFE4= naNdxtOYuAu+68EE17RaSQ8j2PM= Michael Greer DDS 32 6.0 6.0 shoulder 3 None 5.0 ... 0 0.991228 0 0 0 0 0 0 0 shoulder_internal_rotation <p>74790 rows \u00d7 34 columns</p> In\u00a0[6]: Copied! <pre>def identify_first_exercise_skipped(df: pd.DataFrame, grouped: pd.DataFrame) -&gt; pd.DataFrame:\n    \"\"\"Identify the first exercise skipped by the patient.\n    \n    Parameters\n    ----------\n    df : pd.DataFrame\n        Raw exercise results data.\n    grouped : pd.DataFrame\n        Aggregated session data.\n        \n    Returns\n    -------\n    pd.DataFrame\n        Session data with first skipped exercise added.\n    \"\"\"\n    skipped_exercises = df[df[\"leave_exercise\"].notnull()].sort_values(by=[\"session_group\", \"exercise_order\"])\n    first_skipped = skipped_exercises.groupby(\"session_group\").first().reset_index()[[\"session_group\", \"exercise_name\"]]\n    grouped = grouped.merge(first_skipped, on=\"session_group\", how=\"left\")\n    grouped.rename(columns={\"exercise_name\": \"first_exercise_skipped\"}, inplace=True)\n    return grouped\n\ndf_step_6 = identify_first_exercise_skipped(df, df_step_5)\ndf_step_6\n</pre> def identify_first_exercise_skipped(df: pd.DataFrame, grouped: pd.DataFrame) -&gt; pd.DataFrame:     \"\"\"Identify the first exercise skipped by the patient.          Parameters     ----------     df : pd.DataFrame         Raw exercise results data.     grouped : pd.DataFrame         Aggregated session data.              Returns     -------     pd.DataFrame         Session data with first skipped exercise added.     \"\"\"     skipped_exercises = df[df[\"leave_exercise\"].notnull()].sort_values(by=[\"session_group\", \"exercise_order\"])     first_skipped = skipped_exercises.groupby(\"session_group\").first().reset_index()[[\"session_group\", \"exercise_name\"]]     grouped = grouped.merge(first_skipped, on=\"session_group\", how=\"left\")     grouped.rename(columns={\"exercise_name\": \"first_exercise_skipped\"}, inplace=True)     return grouped  df_step_6 = identify_first_exercise_skipped(df, df_step_5) df_step_6  Out[6]: session_group patient_id patient_name patient_age pain fatigue therapy_name session_number leave_session quality ... perc_correct_repeats leave_exercise_system_problem leave_exercise_other leave_exercise_unable_perform leave_exercise_pain leave_exercise_tired leave_exercise_technical_issues leave_exercise_difficulty exercise_with_most_incorrect first_exercise_skipped 0 ++//wixk6DpH8NMGvqLqvpzWbzY= 3FDm7kzjNVgmqUPhyODoZpMIIGc= Taylor Mendez 55 6.0 4.0 shoulder 6 None 4.0 ... 0.989583 0 0 0 0 0 0 0 shoulder_abduction NaN 1 ++2JgoMe8JGBtUHdsOiLGO8UZ18= KRnwvSlSa6U62Edl3dHJa0nVM5A= Danielle Miller 75 4.0 0.0 knee 8 None 5.0 ... 0.995 0 0 0 0 0 0 0 hip_abduction NaN 2 ++4kUzy7ewH5u7FjNoU8CW6thbY= euuPYQwygUQC94V0LvmFOzHPoXQ= Jeremy Randall 70 4.0 2.0 low_back 9 None 5.0 ... 0.993333 0 0 0 0 0 0 0 hip_hyperextension NaN 3 ++8Q+lFKrp9IKCWsBT0IO0XEV1Y= R0S8jUhp1lC00zuUYuB0QAnj6as= Richard Robinson 98 4.0 4.0 low_back 2 None 4.0 ... 0.88 0 0 0 0 0 0 0 knee_flexion NaN 4 ++9PC4/46Jmrl/PHbzkM1BCPg2g= Uj48yKb4R53oteHJHRcnzpUjBdY= Hector Perry 28 2.0 2.0 knee 17 None 5.0 ... 0.986395 0 0 0 0 0 0 0 airplane NaN ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... 74785 zzjYItanfFoaxcOT72WuLVdFlpU= p5r85M4UOxA+ooLsAnpGA091yec= Brianna George 28 2.0 0.0 shoulder 11 None 5.0 ... 0.968182 0 0 0 0 0 0 0 diagonal_1_flexion NaN 74786 zzkMg0F+Nr92E2UwQld7T2c9DxY= Q8xrPkPRSOYhbjrzTxF77Fp40IA= Sophia Harris 85 8.0 4.0 neck 13 None 5.0 ... 0.992958 0 0 0 0 0 0 0 sitting_neck_side_bending NaN 74787 zzwyhOME0/jCt/TlocGDlnM7Nx4= 4tqtZxzLS9+7QJtKa3pW0beUG3s= Donna Moreno 34 0.0 0.0 elbow 13 None 5.0 ... 0.990741 0 0 0 0 0 0 0 diagonal_1_flexion NaN 74788 zzy4uJWf1oWcSbMEHF4RG15ELcU= bWap/fmf6koGTRDMpejv7/J+ovw= Nancy Walter 96 4.0 0.0 low_back 1 None 3.0 ... 0.949153 0 0 0 0 0 0 0 hip_hyperextension NaN 74789 zzywE42oNH4kWtcuDUxFj4IHFE4= naNdxtOYuAu+68EE17RaSQ8j2PM= Michael Greer DDS 32 6.0 6.0 shoulder 3 None 5.0 ... 0.991228 0 0 0 0 0 0 0 shoulder_internal_rotation NaN <p>74790 rows \u00d7 35 columns</p> In\u00a0[7]: Copied! <pre>def order_columns(grouped: pd.DataFrame) -&gt; pd.DataFrame:\n    \"\"\"Order columns in a logical sequence.\n    \n    Parameters\n    ----------\n    grouped : pd.DataFrame\n        Session data with all features.\n        \n    Returns\n    -------\n    pd.DataFrame\n        Session data with columns in the specified order.\n    \"\"\"\n    columns_order = [\n        \"session_group\",\n        \"patient_id\",\n        \"patient_name\",\n        \"patient_age\",\n        \"pain\",\n        \"fatigue\",\n        \"therapy_name\",\n        \"session_number\",\n        \"leave_session\",\n        \"quality\",\n        \"quality_reason_movement_detection\",\n        \"quality_reason_my_self_personal\",\n        \"quality_reason_other\",\n        \"quality_reason_exercises\",\n        \"quality_reason_tablet\",\n        \"quality_reason_tablet_and_or_motion_trackers\",\n        \"quality_reason_easy_of_use\",\n        \"quality_reason_session_speed\",\n        \"session_is_nok\",\n        \"leave_exercise_system_problem\",\n        \"leave_exercise_other\",\n        \"leave_exercise_unable_perform\",\n        \"leave_exercise_pain\",\n        \"leave_exercise_tired\",\n        \"leave_exercise_technical_issues\",\n        \"leave_exercise_difficulty\",\n        \"prescribed_repeats\",\n        \"training_time\",\n        \"perc_correct_repeats\",\n        \"number_exercises\",\n        \"number_of_distinct_exercises\",\n        \"exercise_with_most_incorrect\",\n        \"first_exercise_skipped\",\n        ]\n    grouped = grouped[columns_order]\n\n    return grouped\n\ndf_step_7 = order_columns(df_step_6)\ndf_step_7\n</pre> def order_columns(grouped: pd.DataFrame) -&gt; pd.DataFrame:     \"\"\"Order columns in a logical sequence.          Parameters     ----------     grouped : pd.DataFrame         Session data with all features.              Returns     -------     pd.DataFrame         Session data with columns in the specified order.     \"\"\"     columns_order = [         \"session_group\",         \"patient_id\",         \"patient_name\",         \"patient_age\",         \"pain\",         \"fatigue\",         \"therapy_name\",         \"session_number\",         \"leave_session\",         \"quality\",         \"quality_reason_movement_detection\",         \"quality_reason_my_self_personal\",         \"quality_reason_other\",         \"quality_reason_exercises\",         \"quality_reason_tablet\",         \"quality_reason_tablet_and_or_motion_trackers\",         \"quality_reason_easy_of_use\",         \"quality_reason_session_speed\",         \"session_is_nok\",         \"leave_exercise_system_problem\",         \"leave_exercise_other\",         \"leave_exercise_unable_perform\",         \"leave_exercise_pain\",         \"leave_exercise_tired\",         \"leave_exercise_technical_issues\",         \"leave_exercise_difficulty\",         \"prescribed_repeats\",         \"training_time\",         \"perc_correct_repeats\",         \"number_exercises\",         \"number_of_distinct_exercises\",         \"exercise_with_most_incorrect\",         \"first_exercise_skipped\",         ]     grouped = grouped[columns_order]      return grouped  df_step_7 = order_columns(df_step_6) df_step_7 Out[7]: session_group patient_id patient_name patient_age pain fatigue therapy_name session_number leave_session quality ... leave_exercise_tired leave_exercise_technical_issues leave_exercise_difficulty prescribed_repeats training_time perc_correct_repeats number_exercises number_of_distinct_exercises exercise_with_most_incorrect first_exercise_skipped 0 ++//wixk6DpH8NMGvqLqvpzWbzY= 3FDm7kzjNVgmqUPhyODoZpMIIGc= Taylor Mendez 55 6.0 4.0 shoulder 6 None 4.0 ... 0 0 0 96 356 0.989583 8 8 shoulder_abduction NaN 1 ++2JgoMe8JGBtUHdsOiLGO8UZ18= KRnwvSlSa6U62Edl3dHJa0nVM5A= Danielle Miller 75 4.0 0.0 knee 8 None 5.0 ... 0 0 0 200 767 0.995 19 10 hip_abduction NaN 2 ++4kUzy7ewH5u7FjNoU8CW6thbY= euuPYQwygUQC94V0LvmFOzHPoXQ= Jeremy Randall 70 4.0 2.0 low_back 9 None 5.0 ... 0 0 0 150 683 0.993333 18 12 hip_hyperextension NaN 3 ++8Q+lFKrp9IKCWsBT0IO0XEV1Y= R0S8jUhp1lC00zuUYuB0QAnj6as= Richard Robinson 98 4.0 4.0 low_back 2 None 4.0 ... 0 0 0 50 279 0.88 7 7 knee_flexion NaN 4 ++9PC4/46Jmrl/PHbzkM1BCPg2g= Uj48yKb4R53oteHJHRcnzpUjBdY= Hector Perry 28 2.0 2.0 knee 17 None 5.0 ... 0 0 0 147 466 0.986395 16 11 airplane NaN ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... 74785 zzjYItanfFoaxcOT72WuLVdFlpU= p5r85M4UOxA+ooLsAnpGA091yec= Brianna George 28 2.0 0.0 shoulder 11 None 5.0 ... 0 0 0 220 731 0.968182 23 12 diagonal_1_flexion NaN 74786 zzkMg0F+Nr92E2UwQld7T2c9DxY= Q8xrPkPRSOYhbjrzTxF77Fp40IA= Sophia Harris 85 8.0 4.0 neck 13 None 5.0 ... 0 0 0 142 750 0.992958 18 11 sitting_neck_side_bending NaN 74787 zzwyhOME0/jCt/TlocGDlnM7Nx4= 4tqtZxzLS9+7QJtKa3pW0beUG3s= Donna Moreno 34 0.0 0.0 elbow 13 None 5.0 ... 0 0 0 216 556 0.990741 18 8 diagonal_1_flexion NaN 74788 zzy4uJWf1oWcSbMEHF4RG15ELcU= bWap/fmf6koGTRDMpejv7/J+ovw= Nancy Walter 96 4.0 0.0 low_back 1 None 3.0 ... 0 0 0 118 693 0.949153 13 7 hip_hyperextension NaN 74789 zzywE42oNH4kWtcuDUxFj4IHFE4= naNdxtOYuAu+68EE17RaSQ8j2PM= Michael Greer DDS 32 6.0 6.0 shoulder 3 None 5.0 ... 0 0 0 114 544 0.991228 10 8 shoulder_internal_rotation NaN <p>74790 rows \u00d7 33 columns</p> In\u00a0[8]: Copied! <pre>def transform_features_py() -&gt; pd.DataFrame:\n    \"\"\"Loads the exercise results and transforms them into features.\n    \n    Returns\n    -------\n    pd.DataFrame\n        The transformed features.\n    \"\"\"\n\n    df = load_exercise_data(DATA_DIR)\n    grouped = aggregate_session_data(df)\n    grouped = calculate_performance_metrics(grouped)\n    grouped = add_reason_counts(df, grouped)\n    grouped = identify_first_exercise_skipped(df, grouped)\n    grouped = identify_most_incorrect_exercise(df, grouped)\n    grouped = order_columns(grouped)\n\n    return grouped\n\ndf_final = transform_features_py()\ndf_final\n</pre> def transform_features_py() -&gt; pd.DataFrame:     \"\"\"Loads the exercise results and transforms them into features.          Returns     -------     pd.DataFrame         The transformed features.     \"\"\"      df = load_exercise_data(DATA_DIR)     grouped = aggregate_session_data(df)     grouped = calculate_performance_metrics(grouped)     grouped = add_reason_counts(df, grouped)     grouped = identify_first_exercise_skipped(df, grouped)     grouped = identify_most_incorrect_exercise(df, grouped)     grouped = order_columns(grouped)      return grouped  df_final = transform_features_py() df_final  Out[8]: session_group patient_id patient_name patient_age pain fatigue therapy_name session_number leave_session quality ... leave_exercise_tired leave_exercise_technical_issues leave_exercise_difficulty prescribed_repeats training_time perc_correct_repeats number_exercises number_of_distinct_exercises exercise_with_most_incorrect first_exercise_skipped 0 ++//wixk6DpH8NMGvqLqvpzWbzY= 3FDm7kzjNVgmqUPhyODoZpMIIGc= Taylor Mendez 55 6.0 4.0 shoulder 6 None 4.0 ... 0 0 0 96 356 0.989583 8 8 shoulder_abduction NaN 1 ++2JgoMe8JGBtUHdsOiLGO8UZ18= KRnwvSlSa6U62Edl3dHJa0nVM5A= Danielle Miller 75 4.0 0.0 knee 8 None 5.0 ... 0 0 0 200 767 0.995 19 10 hip_abduction NaN 2 ++4kUzy7ewH5u7FjNoU8CW6thbY= euuPYQwygUQC94V0LvmFOzHPoXQ= Jeremy Randall 70 4.0 2.0 low_back 9 None 5.0 ... 0 0 0 150 683 0.993333 18 12 hip_hyperextension NaN 3 ++8Q+lFKrp9IKCWsBT0IO0XEV1Y= R0S8jUhp1lC00zuUYuB0QAnj6as= Richard Robinson 98 4.0 4.0 low_back 2 None 4.0 ... 0 0 0 50 279 0.88 7 7 knee_flexion NaN 4 ++9PC4/46Jmrl/PHbzkM1BCPg2g= Uj48yKb4R53oteHJHRcnzpUjBdY= Hector Perry 28 2.0 2.0 knee 17 None 5.0 ... 0 0 0 147 466 0.986395 16 11 airplane NaN ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... 74785 zzjYItanfFoaxcOT72WuLVdFlpU= p5r85M4UOxA+ooLsAnpGA091yec= Brianna George 28 2.0 0.0 shoulder 11 None 5.0 ... 0 0 0 220 731 0.968182 23 12 diagonal_1_flexion NaN 74786 zzkMg0F+Nr92E2UwQld7T2c9DxY= Q8xrPkPRSOYhbjrzTxF77Fp40IA= Sophia Harris 85 8.0 4.0 neck 13 None 5.0 ... 0 0 0 142 750 0.992958 18 11 sitting_neck_side_bending NaN 74787 zzwyhOME0/jCt/TlocGDlnM7Nx4= 4tqtZxzLS9+7QJtKa3pW0beUG3s= Donna Moreno 34 0.0 0.0 elbow 13 None 5.0 ... 0 0 0 216 556 0.990741 18 8 diagonal_1_flexion NaN 74788 zzy4uJWf1oWcSbMEHF4RG15ELcU= bWap/fmf6koGTRDMpejv7/J+ovw= Nancy Walter 96 4.0 0.0 low_back 1 None 3.0 ... 0 0 0 118 693 0.949153 13 7 hip_hyperextension NaN 74789 zzywE42oNH4kWtcuDUxFj4IHFE4= naNdxtOYuAu+68EE17RaSQ8j2PM= Michael Greer DDS 32 6.0 6.0 shoulder 3 None 5.0 ... 0 0 0 114 544 0.991228 10 8 shoulder_internal_rotation NaN <p>74790 rows \u00d7 33 columns</p> In\u00a0[9]: Copied! <pre>from message.data import transform_features_py as transform_features_py_mod\ndf_features_mod = transform_features_py_mod()\n</pre>  from message.data import transform_features_py as transform_features_py_mod df_features_mod = transform_features_py_mod()  In\u00a0[10]: Copied! <pre>df_features_mod.describe()\n</pre> df_features_mod.describe() Out[10]: patient_age pain fatigue session_number quality quality_reason_movement_detection quality_reason_my_self_personal quality_reason_other quality_reason_exercises quality_reason_tablet ... leave_exercise_unable_perform leave_exercise_pain leave_exercise_tired leave_exercise_technical_issues leave_exercise_difficulty prescribed_repeats training_time perc_correct_repeats number_exercises number_of_distinct_exercises count 74790.000000 68575.000000 68573.000000 74790.000000 68312.000000 74790.000000 74790.000000 74790.000000 74790.000000 74790.000000 ... 74790.000000 74790.000000 74790.000000 74790.0 74790.0 74790.0 74790.0 74790.0 74790.000000 74790.000000 mean 58.582992 2.479533 1.800067 28.571814 4.505475 0.116393 0.067509 0.048696 0.046089 0.013892 ... 0.034029 0.022182 0.009039 0.0 0.0 135.370825 592.987458 &lt;NA&gt; 15.064233 8.792258 std 23.773241 2.065735 1.996785 55.128341 0.806024 0.320697 0.250903 0.215234 0.209679 0.117045 ... 0.319079 0.253819 0.201078 0.0 0.0 53.943975 258.906156 &lt;NA&gt; 5.526578 2.418361 min 18.000000 0.000000 0.000000 1.000000 1.000000 0.000000 0.000000 0.000000 0.000000 0.000000 ... 0.000000 0.000000 0.000000 0.0 0.0 1.0 0.0 &lt;NA&gt; 1.000000 1.000000 25% 38.000000 0.000000 0.000000 5.000000 4.000000 0.000000 0.000000 0.000000 0.000000 0.000000 ... 0.000000 0.000000 0.000000 0.0 0.0 94.0 397.0 &lt;NA&gt; 10.000000 7.000000 50% 58.000000 2.000000 2.000000 11.000000 5.000000 0.000000 0.000000 0.000000 0.000000 0.000000 ... 0.000000 0.000000 0.000000 0.0 0.0 134.0 569.0 &lt;NA&gt; 15.000000 9.000000 75% 79.000000 4.000000 2.000000 26.000000 5.000000 0.000000 0.000000 0.000000 0.000000 0.000000 ... 0.000000 0.000000 0.000000 0.0 0.0 177.0 757.0 &lt;NA&gt; 20.000000 11.000000 max 99.000000 10.000000 10.000000 812.000000 5.000000 1.000000 1.000000 1.000000 1.000000 1.000000 ... 13.000000 11.000000 16.000000 0.0 0.0 725.0 5123.0 &lt;NA&gt; 54.000000 43.000000 <p>8 rows \u00d7 25 columns</p>"},{"location":"Question_1/#question-1","title":"Question 1\u00b6","text":"<p>This notebook breaks down the <code>transform_features_py</code> function that transforms raw exercise results data into aggregated features.</p>"},{"location":"Question_1/#data","title":"Data\u00b6","text":""},{"location":"Question_1/#input-data-structure","title":"Input Data Structure\u00b6","text":"<p>The input data contains exercise results with columns including:</p> Field Meaning <code>session_exercise_result_id</code> Identifier of an exercise performed by a patient in a given moment in time (primary key). Each time a patient performs the same exercise, even if in the same session, it will have a different <code>session_exercise_result_id</code>. <code>session_group</code> Identifier of the physical therapy session in which this exercise was performed. Each time a patient performs a session it will have a different <code>session_group</code> (all exercises of the same session will have the same value). <code>patient_id</code> Identifier of the patient that performed the session  (all sessions of the same patient will have the same value). <code>patient_name</code> Name of the patient that performed the session (all sessions of the same patient will have the same value). <code>patient_age</code> Age of the patient that performed the session (all sessions of the same patient will have the same value). <code>exercise_name</code> Name of the performed exercise. <code>exercise_side</code> Body side that the exercise regards. <code>exercise_order</code> Order of the exercise within the session (the first exercise of the session has <code>order</code> 1, the second has <code>order</code> 2 and so on). <code>prescribed_repeats</code> Number of repetitions (individual movements) the patient was supposed to perform in this specific exercise. Can be different among two performances of the same exercise in the same session. The exercise finishes when the number of performed repetitions - either correct or wrong - reaches this value. <code>training_time</code> Time, in seconds, the patient spent performing the exercise <code>correct_repeats</code> Number of correct repetitions performed. <code>wrong_repeats</code> Number of incorrect repetitions performed. <code>leave_exercise</code> If the patient leaves the exercise before finishing it, this field stores the reason why. If the patient leaves the exercise, he is led into the following exercise in the session. <code>leave_session</code> If the patient leaves the session before finishing it, this field stores the reason why (all exercises of the same session will have the same value). If the patient leaves the session, no more exercises are performed. <code>pain</code> Amount of pain between reported by the patient at the end of the session where this exercise was performed, between 0 and 10, where 0 is no pain and 10 is the worst possible pain (all exercises of the same session will have the same value). <code>fatigue</code> Amount of fatigue between reported by the patient at the end of the session where this exercise was performed, between 0 and 10, where 0 is no fatigue and 10 is the worst possible fatigue (all exercises of the same session will have the same value). <code>therapy_name</code> Name of the therapy the patient is undertaking (the same for all exercises in the same session). <code>session_number</code> Session number for that patient. The first session performed by the patient will have <code>session_number</code> equal to 1, the second 2, ... (the same for all exercises in the same session). <code>quality</code> Score from 1 to 5 reported by the patient at the end of the session when replying to the \"How would you rate your experience today?\" question (all exercises of the same session will have the same value). <code>quality_reason_*</code> Additional context collected when a quality bellow 5 is reported by the patient (see image bellow). Possible values are <code>movement_detection</code>, <code>my_self_personal</code>, <code>other</code>, <code>exercises</code>, <code>tablet</code>, <code>tablet_and_or_motion_trackers</code>, <code>easy_of_use</code>, <code>session_speed</code> (all exercises of the same session will have the same value). <code>session_is_nok</code> Classification model score on each session (1 corresponds to a <code>nok</code> session and 0 to an <code>ok</code> session)."},{"location":"Question_1/#output-data-structure","title":"Output Data Structure\u00b6","text":"<p>The <code>transform_features_py</code> trasnforms data such that each row is indexed by <code>session_group</code> and has the following fields:</p> Field Meaning <code>session_group</code> explained above (primary key) <code>patient_id</code> explained above <code>patient_name</code> explained above <code>patient_age</code> explained above <code>pain</code> explained above <code>fatigue</code> explained above <code>therapy_name</code> explained above <code>session_number</code> explained above <code>leave_session</code> explained above <code>quality</code> explained above <code>quality_reason_*</code> explained above <code>session_is_nok</code> explained above <code>leave_exercise_*</code> Number of exercises in the session that were left due to reason <code>system_problem</code>, <code>other</code>, <code>unable_perform</code>, <code>pain</code> and <code>tired</code>, <code>technical_issues</code>, <code>difficulty</code> respectively. <code>prescribed_repeats</code> Total number of repetitions (among all exercises) the patient was supposed to perform. <code>training_time</code> Time, in seconds, the patient spent performing the session. <code>perc_correct_repeats</code> Percentage of correct repetitions in the session. <code>number_exercises</code> Number of exercises performed in the session. <code>number_of_distinct_exercises</code> Number of distinct exercises performed in the session. <code>exercise_with_most_incorrect</code> Name of the exercise with the highest number of incorrect movements, if any. If there are two with the highest number of incorrect movement, you can pick any of them. <code>first_exercise_skipped</code> Name of the first skipped exercise, if any."},{"location":"Question_1/#transformations-breakdown","title":"Transformations Breakdown\u00b6","text":"<p>These are the applied transformations:</p> <ol> <li>Aggregation: Condenses multiple exercise rows into a single session row</li> <li>Feature Engineering: Creates derived metrics like percentage of correct repetitions</li> <li>Categorization: Creates indicator columns for reasons exercises were left or quality issues</li> <li>Problem Detection: Identifies problematic exercises (most incorrect, first skipped)</li> </ol>"},{"location":"Question_1/#code-breakdown","title":"Code Breakdown\u00b6","text":"<p>The code is split into two modules:</p> <ul> <li><code>io.py</code>: handles file io; <code>load_exercise_data</code> for this question specifcally.</li> <li><code>transform.py</code>: contains all applicable transformations to the exercise results.</li> <li><code>data.py</code>: contains the <code>transform_features_py</code> function that leverages the <code>transform</code> module to transform the exercise results into features.</li> <li>Tests: tests are located in the <code>tests/data_test.py</code> module. For more information refer to Question 1 - Testing Structure and Methodology</li> </ul>"},{"location":"Question_1/#step-by-step-guide","title":"Step by Step Guide\u00b6","text":"<p>This breaks down the <code>transform_features_py</code> function and its components. The function transforms raw exercise results data into aggregated features.</p>"},{"location":"Question_1/#quick-overview","title":"Quick Overview\u00b6","text":"<p><code>transform_features_py</code> is the main functions that orchestrates the entire process, and composed of the following functions:</p> <ol> <li><code>load_exercise_data</code> - Handles data loading from the parquet file</li> <li><code>aggregate_session_data</code> - Performs the initial groupby and aggregation</li> <li><code>calculate_performance_metrics</code> - Adds calculated metrics like percentage of correct repetitions</li> <li><code>add_reason_counts</code> - Adds columns for counting different reasons for leaving exercises or quality issues</li> <li><code>identify_first_exercise_skipped</code> - Identifies the first exercise skipped by the patient</li> <li><code>identify_most_incorrect_exercise</code> - Identifies exercises with problems (most incorrect)</li> <li><code>order_columns</code> - Orders the columns in a logical sequence</li> </ol> <p>Each function has a single responsibility and a clear purpose, which allows testing each component separately. It also makes the code easier to maintain and reuse, since it's easier to modify specific parts without affecting the whole.</p>"},{"location":"Question_1/#1-load-the-data-load_exercise_data","title":"1. Load the Data - <code>load_exercise_data</code>\u00b6","text":"<p>Read a Parquet file containing the exercise results data into a pandas DataFrame.</p>"},{"location":"Question_1/#2-group-and-aggregate-data-aggregate_session_data","title":"2. Group and Aggregate Data - <code>aggregate_session_data</code>\u00b6","text":"<p>Apply simple aggregations:</p> <ol> <li>Groups the data by <code>session_group</code></li> <li>Apply different aggregation functions:<ul> <li><code>first</code>: Takes the first value in each group for patient info and session details</li> <li><code>sum</code>: Adds up numerical values across all exercises in the session</li> <li><code>count</code>: Counts the total number of exercises</li> <li><code>nunique</code>: Counts the number of distinct exercises</li> </ul> </li> <li>Apply type coercions</li> </ol>"},{"location":"Question_1/#3-calculate-percentage-of-correct-repetitions-calculate_performance_metrics","title":"3. Calculate Percentage of Correct Repetitions: <code>calculate_performance_metrics</code>\u00b6","text":"<p>Creates a new feature measuring exercise accuracy by dividing the correct repetitions by the total repetitions.</p>"},{"location":"Question_1/#4-process-reasons-for-leaving-exercises-add_reason_counts","title":"4. Process Reasons for Leaving Exercises: <code>add_reason_counts</code>\u00b6","text":"<p>Adds columns that count how many times each reason was recorded for leaving an exercise:</p> <ol> <li>Creates a list of predefined reasons why users might leave an exercise</li> <li>Set Index for faster lookup</li> <li>Count Reasons and Update the Data<ol> <li>Adds a new column to grouped initialized to 0</li> <li>Filters <code>df</code> to find rows where leave exercise matches the current reason: <code>df[df[\"leave_exercise\"] == reason]</code></li> <li>Groups by \"session_group\" and counts occurrences of the reason: <code>.groupby(\"session_group\")[\"leave_exercise\"].count()</code></li> <li>Updates grouped with these counts: <code>grouped.loc[df_leave_exercise.index, f\"leave_exercise_{reason}\"] = df_leave_exercise.values</code></li> <li>Fills NaN values with 0 to ensure consistency.</li> </ol> </li> <li>Reset Index</li> <li>Resets the index of grouped after aggregation to restore \"session_group\" as a column.</li> </ol> <p>Reset is inefficient but necessary for further operations.</p>"},{"location":"Question_1/#5-identify-skipped-exercise-identify_problematic_exercises","title":"5. Identify Skipped Exercise: <code>identify_problematic_exercises</code>\u00b6","text":"<p>Exercises that had the most incorrect repetitions:</p> <ol> <li>Groups <code>df</code> by \"session_group\" and \"exercise_name\"</li> <li>Sums the \"wrong_repeats\" column to get the total incorrect repetitions for each exercise in each session</li> <li>Finds the exercise with the highest \"wrong_repeats\" count for each \"session_group\" (<code>grouped_wrong_reps.loc[grouped_wrong_reps.groupby(\"session_group\")[\"wrong_repeats\"].idxmax()]</code>)</li> <li>Drops the \"wrong_repeats\" column after identifying the most incorrect exercise</li> <li>Merges the identified most incorrect exercises into <code>grouped</code> using \"session_group\" as the key. Uses a left join to retain all session data, even if no incorrect repetitions exist</li> <li>Renames \"exercise_name\" to \"exercise_with_most_incorrect\"</li> </ol>"},{"location":"Question_1/#6-identify-first-skipepd-exercise-identify_first_exercise_skipped","title":"6. Identify first skipepd exercise: <code>identify_first_exercise_skipped</code>\u00b6","text":"<p>The first exercise skipped in each session by:</p> <ol> <li>Filtering for exercises where <code>leave_exercise</code> is not null (skipped exercises)</li> <li>Sorting by session group and exercise order</li> <li>Getting the first skipped exercise for each session group</li> <li>Merging this information back into the grouped DataFrame</li> <li>Renaming the column to <code>first_exercise_skipped</code></li> </ol>"},{"location":"Question_1/#7-define-column-order-and-return-final-dataframe-order_columns","title":"7. Define Column Order and Return Final DataFrame: <code>order_columns</code>\u00b6","text":"<p>Orders output columns accordingly to question description:</p> <ol> <li>Defines a specific column order for the output</li> <li>Returns the grouped DataFrame with the specified column order</li> </ol>"},{"location":"Question_1/#8-putting-it-all-together-transform_features_py","title":"8. Putting it all together - <code>transform_features_py</code>\u00b6","text":"<p>Function was modified to call all of the above sequentially to obtain the pretended features.</p>"},{"location":"Question_1/#running-from-module","title":"Running from module\u00b6","text":"<p>Finally we call the implmentation directly from the module.</p>"},{"location":"Question_1_Tests/","title":"Question 1 - Testing Structure and Methodology","text":"<p>This document outlines the testing strategy used for validating the <code>transform_features_py</code> function. The test suite is built using <code>pytest</code>. It leverages parameterized tests and fixtures.</p> <p>Tests are located in <code>tests/data_test.py</code>.</p>"},{"location":"Question_1_Tests/#test-data-preparation","title":"Test Data Preparation","text":"<p>Two key datasets are used in the tests: - <code>Expected Dataframe</code>: The expected transformed dataset loaded from a pre-generated Parquet file (<code>features_expected.parquet</code>), which serves as a benchmark. - <code>Result Dataframe</code>: The actual transformed dataset generated by running <code>transform_features_py()</code>.</p>"},{"location":"Question_1_Tests/#fixtures","title":"Fixtures","text":"<p>To avoid redundant computations and improve efficiency, two session-scoped fixtures are used: - <code>expected_df</code>: Loads and preprocesses the expected dataset once per test session. - <code>result_df</code>: Runs the transformation function once per test session and stores the result. - <code>exercise_with_most_incorrect_df</code>: Loads the pre-generated Parquet file containing two columns, <code>exercise_with_most_incorrect_trans</code> (from the original dataset) and <code>exercise_with_most_incorrect_session</code> (from the original dataset).</p> <p>Setting up a scope for the fixtures, via the <code>@pytest.fixture(scope=\"session\")</code> decorator, ensures that the datasets are loaded and processed only once per test session, which increases tests speed.</p> <p>Both datasets are reset to have sequential indexing and sorted based on the <code>session_group</code> column to maintain consistency in comparisons.</p> <p>To make sure that the produced output was correct, the whole dataset is compared.</p> <p>Noticeable Anti-Pattern: the tested function's result is used as a fixture, which is not  best practice (I've never seen it before). This is because the dataset is large enough that it would take too long to run the function for all tests. This way, the function is only run once per test session, significantly improving performance.</p> <pre><code>@pytest.fixture(scope=\"session\")\ndef result_df():\n    df = transform_features_py().reset_index(drop=True).sort_values(\"session_group\")\n    return df\n</code></pre>"},{"location":"Question_1_Tests/#test-cases","title":"Test Cases","text":""},{"location":"Question_1_Tests/#column-wise-equality-tests","title":"Column-Wise Equality Tests","text":"<p>Parameterized tests ensure that each specified column in the transformed dataset matches the expected values exactly. The following columns are checked: <code>session_group</code>, <code>patient_id</code>, <code>patient_name</code>, <code>patient_age</code>, <code>pain</code>, <code>fatigue</code>, <code>therapy_name</code>, <code>session_number</code>, <code>leave_session</code>, <code>quality</code>, <code>quality_reason_movement_detection</code>, <code>quality_reason_my_self_personal</code>, <code>quality_reason_other</code>, <code>quality_reason_exercises</code>, <code>quality_reason_tablet</code>, <code>quality_reason_tablet_and_or_motion_trackers</code>, <code>quality_reason_easy_of_use</code>, <code>quality_reason_session_speed</code>, <code>prescribed_repeats</code>, <code>training_time</code>, <code>number_exercises</code>, <code>number_of_distinct_exercises</code>.</p> <p>The test function <code>test_transform_features_py_column</code> ensures that all values in these columns match using <code>numpy.testing.assert_array_equal</code>.</p> <pre><code>@pytest.mark.parametrize(\"column\",[\n    \"session_group\",\n    ...\n    \"number_of_distinct_exercises\",\n])\ndef test_transform_features_py_column(result_df, expected_df, column):\n    assert_array_equal(result_df[column].values, expected_df[column].values)\n</code></pre>"},{"location":"Question_1_Tests/#floating-point-precision-test","title":"Floating Point Precision Test","text":"<p>Computational errors with floating points are mitigated by scaling the <code>perc_correct_repeats</code> column by 10,000 (to account for 2 decimal places) and converting it to an integer before comparison (<code>test_perc_correct_repeats</code>). This technique is common practice in financial computing.</p> <pre><code>def test_perc_correct_repeats(result_df, expected_df):\n    # computers don't like floats, so we multiply by 10,000 and convert to int\n    # this will give us 2 decimal places precision\n    assert_array_equal(\n        (result_df[\"perc_correct_repeats\"].values * 10000.0).astype(int),\n        (expected_df[\"perc_correct_repeats\"].values * 10000.0).astype(int))\n</code></pre>"},{"location":"Question_1_Tests/#validating-session_is_nok-handling-missing-values","title":"Validating <code>session_is_nok</code> - Handling Missing Values","text":"<p>The <code>session_is_nok</code> column may contain missing values. The test <code>test_session_is_nok</code> replaces NaN values with <code>-1</code> before asserting equality, thus treating the boolean column as an integer. This is to prevent <code>assert_array_equal</code> from failing due to missing values.</p> <pre><code>def test_session_is_nok(result_df, expected_df):\n    assert_array_equal(\n        result_df[\"session_is_nok\"].fillna(-1).values,\n        expected_df[\"session_is_nok\"].fillna(-1).values\n    )\n</code></pre>"},{"location":"Question_1_Tests/#leave-exercise-validation","title":"Leave Exercise Validation","text":"<p>The <code>leave_exercise_*</code> columns are treated as integers to facilitate comparison.</p> <pre><code>@pytest.mark.parametrize(\"column\",[\n    \"leave_exercise_system_problem\",\n    ...\n    \"leave_exercise_difficulty\",\n])\ndef test_leave_exercise(result_df, expected_df, column):\n    assert_array_equal(\n        result_df[column].values.astype(int),\n        expected_df[column].values.astype(int)\n    )\n</code></pre>"},{"location":"Question_1_Tests/#string-column-handling","title":"String Column Handling","text":"<p>Columns containing string values, such as <code>first_exercise_skipped</code>, are compared after filling missing values with a placeholder (<code>-</code>).</p> <pre><code>def test_identify_first_exercise_skipped(result_df, expected_df):\n    assert_array_equal(\n        result_df[\"first_exercise_skipped\"].fillna(\"-\").values,\n        expected_df[\"first_exercise_skipped\"].fillna(\"-\").values\n    )\n</code></pre>"},{"location":"Question_1_Tests/#matching-for-ambiguous-cases","title":"Matching for Ambiguous Cases","text":"<p>For <code>exercise_with_most_incorrect</code>, an exact match is not required since multiple exercises may share the same number of incorrect attempts. Instead, the test asserts that at least one of the columns matches.</p> <pre><code>def test_identify_most_incorrect_exercise(result_df, exercise_with_most_incorrect_df):\n    # mast match a least one\n    trans_col = result_df[\"exercise_with_most_incorrect\"].fillna(\"-\").values ==\\\n    exercise_with_most_incorrect_df[\"exercise_with_most_incorrect_trans\"].fillna(\"-\").values\n\n    session_col = result_df[\"exercise_with_most_incorrect\"].fillna(\"-\").values ==\\\n    exercise_with_most_incorrect_df[\"exercise_with_most_incorrect_session\"].fillna(\"-\").values\n\n    assert np.all((trans_col + session_col) &gt; 0)\n</code></pre>"},{"location":"Question_1_Tests/#conclusion-and-considerations","title":"Conclusion and Considerations","text":"<p>The test suite verifies the correctness of the <code>transform_features_py</code> function by comparing the result with the expected values. It uses parameterized tests and fixtures to handle the data and assertions. It breaks down the tests into smaller, focused tests, to address specific cases.</p> <p>In addition, all functions constituting the <code>transform_features_py</code> function should also be tested, to ensure that they work correctly and that the output is as expected.</p>"},{"location":"Question_2a/","title":"Question 2a","text":""},{"location":"Question_2a/#physical-therapy-chat-application-analysis","title":"Physical Therapy Chat Application Analysis","text":"<p>This application is designed to help Physical Therapists (PTs) communicate with patients through a chat interface. The system enables therapists to review auto-generated follow-up messages, edit them with specific feedback categories, and maintain chat history across sessions.</p>"},{"location":"Question_2a/#component-breakdown","title":"Component Breakdown","text":""},{"location":"Question_2a/#1-chatpy","title":"1. <code>chat.py</code>","text":"<p>The main module containing all functionality: - Chat session management - Message generation via LLM (GPT-4o-mini) - Feedback collection and message refinement - Message acceptance/rejection flow</p> <p>Code components: - <code>FeedbackOption</code> enum: Categories for feedback (<code>tone</code>, <code>generic</code>, <code>engagement</code>, <code>factuality</code>, <code>other</code>) - <code>prompt_for_acceptance()</code>: CLI interface for message review - <code>prompt_for_edit_feedback()</code>: CLI interface for feedback collection - <code>llm()</code>: Interface to the chat model - <code>run_chat()</code>: Main chat loop that orchestrates the entire flow</p>"},{"location":"Question_2a/#2-iopy","title":"2. <code>io.py</code>","text":"<p>Handles file I/O operations: - <code>load_prompts()</code>: Loads system prompts from YAML (<code>prompts/prompts.yml</code>) - <code>load_chat_history()</code>: Loads chat history from JSONL file. File are identified by UUID - <code>save_chat_history()</code>: Persists conversation to JSONL file. File are identified by UUID</p>"},{"location":"Question_2a/#3-mainpy","title":"3. <code>main.py</code>","text":"<p>Entry point with CLI commands (provided): - <code>get_message()</code>: Initiates chat session with specified group</p>"},{"location":"Question_2a/#4-makefile","title":"4. Makefile","text":"<p>The <code>Makefile</code> target was modified to accept a session group identifier:</p> <pre><code>.PHONY: get-message\nget-message:\n    message get-message $(session_group)\n\n</code></pre> <p>Usage: <code>make get-message session_group=&lt;session_group&gt;</code></p>"},{"location":"Question_2a/#workflow-breakdown","title":"Workflow Breakdown","text":"<p>The application can be thought as a state machine, with distinct states: (generate \u2192 review \u2192 accept/edit/reject)</p> <ol> <li>Initialization Process:</li> <li>User invokes <code>make get-message session_group=&lt;session_group&gt;</code> (calls <code>main.py</code>)</li> <li>Main calls <code>run_chat()</code> in <code>chat.py</code></li> <li><code>run_chat()</code> loads session features, prompts, and chat history</li> <li> <p>System initializes chat with base prompt (if chat history is empty) + session data</p> </li> <li> <p>Message Generation Process:</p> </li> <li>Chat history sent to <code>llm()</code> function</li> <li>LLM generates message based on history</li> <li> <p>Message displayed to therapist for review</p> </li> <li> <p>Feedback Loop:</p> </li> <li>If message edited, feedback added to history</li> <li>New message generated incorporating feedback</li> <li> <p>Process repeats until message accepted or rejected</p> </li> <li> <p>Persistence Mechanism:</p> </li> <li>At end of session, <code>save_chat_history()</code> writes to disk</li> <li>Each new session loads previous history for context</li> </ol> <p></p>"},{"location":"Question_2a/#prompts-relationships","title":"Prompts Relationships","text":"<p>There are 2 prompt archetypes: - <code>SYSTEM_BASE</code>: The base prompt that is used to generate the message - <code>SYSTEM_FEEDBACK</code>: The feedback prompt that is used to generate the feedback</p> <p>The <code>SYSTEM_BASE</code> prompt is used to generate the initial message, and the <code>SYSTEM_FEEDBACK</code> prompt is used to generate the feedback.</p> <p>The <code>SYSTEM_FEEDBACK</code> prompt is used to generate the feedback. It depends on the various feedback categories.</p> <p></p>"},{"location":"Question_2a/#code-analysis","title":"Code Analysis","text":""},{"location":"Question_2a/#chatpy","title":"<code>chat.py</code>","text":"<p>This is the core module handling the chat functionality:</p> <p>Imports and Setup:    - Uses <code>StrEnum</code> to define feedback categories    - Imports I/O functions (<code>load_chat_history</code>, <code>load_prompts</code>, <code>save_chat_history</code>)    - Creates a unique UUID for each chat session    - Loads system configuration with <code>get_settings()</code>    - Instantiates the chat model with <code>ChatModel()</code></p> <p>Feedback System:    - <code>FeedbackOption</code> enum defines 5 categories: <code>tone</code>, <code>generic</code>, <code>engagement</code>, <code>factuality</code>, <code>other</code>    - <code>FEEDBACK_PROMPT_MAP</code> dictionary maps each category to specific prompt templates    - These prompts guide the LLM in improving messages based on therapist feedback</p> <p>User Interaction Functions:    - <code>prompt_for_acceptance()</code>: Simple CLI input loop that forces user to choose <code>accept</code>, <code>edit</code>, or <code>reject</code>     - Validation: user must choose one of the options, otherwise the loop will continue    - <code>prompt_for_feedback()</code>: Two-step input collection for feedback category and specific comments     - If no category is provided, the default is <code>other</code>     - If an invalid category is provided, the loop will continue     - Text feedback is only requested if a category is provided (can be empty, defaults to <code>other</code>)     - If no comments are provided, the loop will continue    - Both functions include input validation to ensure proper data capture</p> <p>LLM Interface:    - <code>llm()</code> function wraps the model interface    - Sets temperature to <code>0</code> (for more deterministic outputs)    - Uses <code>gpt-4o-mini</code> model    - Passes the entire message history to maintain context</p> <p>Main Chat Loop (<code>run_chat</code>):    - Loads session data with <code>get_features(session_group=session_group)</code>    - Loads chat history with <code>load_chat_history(chat_id=chat_id)</code>     - Creates new chat file if it does not exist    - Initializes chat history with system prompt if empty    - Enters main loop where:      - Message is generated with LLM      - Therapist reviews and decides action         - For <code>accept</code>: adds message to history         - For <code>edit</code>: collects feedback, adds system instruction + feedback to history, and restarts loop (i.e. generates new message and goes back to therapist review)         - For <code>reject</code>: therapist writes their own message and adds it to history    - Saves chat history at end of session    - Includes exception handling to ensure history is saved even on error (graceful shutdown)</p>"},{"location":"Question_2a/#potential-improvements","title":"Potential Improvements","text":"<p>There are numerous potential improvements that could be made to the application, some include: - Error handling captures all exceptions the same way - The temporary/edited messages remain in chat history permanently. Alternatively, only the final message could be saved. - Chat history is saved synchronously, which could be optimized by using a background task. - All chat history is used in the LLM prompt, which could be optimized by using a smaller subset of the history. - Chat history could be incrementally saved.</p>"},{"location":"Question_2a/#iopy","title":"<code>io.py</code>","text":"<p>This module handles all file operations:</p> <p>Prompt Loading: - <code>load_prompts()</code> reads YAML file from <code>prompts/prompts.yml</code> - Returns dictionary of prompt templates for system and feedback messages</p> <p>Chat History Management: - <code>load_chat_history()</code>: Creates <code>.chats</code> directory if needed, reads JSONL file for chat ID - Returns empty list for new chats, or list of message dictionaries for existing chats - Messages stored as JSON objects, one per line</p> <p>History Saving: - <code>save_chat_history()</code>: Writes messages to JSONL file - Function is async but doesn't use async file operations internally - Overwrites entire file on each save (potential optimization point)</p> <p>File Structure: - Chat histories stored at <code>.chats/{chat_id}.jsonl</code> - Prompts stored at <code>prompts/prompts.yml</code></p>"},{"location":"Question_2a/#mainpy","title":"<code>main.py</code>","text":"<p>The entry point for the application:</p> <p>Command Structure: - Uses Typer for CLI interface - <code>get_message()</code> function wraps the chat functionality - Takes \"session_group\" parameter to identify which patient/session data to load - Uses asyncio to run the async chat function</p> <p>Execution Flow: - Calls <code>run_chat()</code> function from <code>chat.py</code></p>"},{"location":"Question_2a/#prompts","title":"Prompts","text":"<p>The system is configured with several prompt templates. Prompts are loaded from <code>prompts/prompts.yml</code>.</p> <p>Base System Prompt:  - Defines the assistant's role as a physical therapist assistant - Explains importance of chat interactions in remote therapy - Details goals of acknowledging session completion, reinforcing communication, and keeping patients engaged - Provides guidelines and examples for different session outcomes</p> <p>Feedback System Prompt: - Template for improving messages - Incorporates feedback category and specific comments</p> <p>Category-Specific Prompts: - <code>TONE_PROMPT</code>: Focus on conversational language - <code>GENERIC_PROMPT</code>: Ensures proper message structure - <code>ENGAGEMENT_PROMPT</code>: Emphasizes patient engagement - <code>FACTUALITY_PROMPT</code>: Ensures accuracy based on session data - <code>OTHER_PROMPT</code>: Catch-all for specific suggestions</p>"},{"location":"Question_2a/#interaction-examples","title":"Interaction Examples","text":"<p>In this section, we will go through a few examples of chat interactions. We use the same session group <code>++//wixk6DpH8NMGvqLqvpzWbzY=</code> for all examples.</p>"},{"location":"Question_2a/#initial-prompt-startup","title":"Initial Prompt - Startup","text":"<p>In this example we run the chat with session group <code>++//wixk6DpH8NMGvqLqvpzWbzY=</code>:</p> <pre><code>make get-message session_group=++//wixk6DpH8NMGvqLqvpzWbzY=\n</code></pre> <p>The chat will start with the base prompt and the session data.</p> <p></p>"},{"location":"Question_2a/#handling-edits","title":"Handling Edits","text":"<p>This example shows how the chat handles edits with feedback. It purposly show how it handles a bad edit.</p> <ol> <li>The app starts a new chat session with the base prompt and session data.</li> <li>The LLM generates a message, which is displayed to the therapist.</li> <li>The therapist reviews the message and decides to edit it.</li> <li>The therapist misspell the word <code>tone</code> as <code>ton</code>.</li> <li>The app prompts for the category again.</li> <li>The therapist selects <code>tone</code>.</li> <li>The app prompts for the feedback.</li> <li>The therapist provides feedback.</li> <li>The app prompts for the acceptance.</li> <li>The therapist accepts the message.</li> <li>The app saves the chat history (implicit).</li> </ol> <p></p>"},{"location":"Question_2a/#handling-rejections","title":"Handling Rejections","text":"<p>This example shows how the chat handles rejections. We purposly provide an empty feedback to show how the app handles it.</p> <ol> <li>The app starts a new chat session with the base prompt and session data.</li> <li>The LLM generates a message, which is displayed to the therapist.</li> <li>The therapist reviews the message and decides to reject it.</li> <li>The app prompts for an answer.</li> <li>The therapist provides empty feedback.</li> <li>The app prompts for an answer again.</li> <li>The therapist provides an answer.</li> <li>The app saves the chat history (implicit).</li> </ol> <p></p>"},{"location":"Question_2a/#hanling-empty-category","title":"Hanling Empty Category","text":"<p>This example shows how the chat handles empty category inputs.</p> <ol> <li>The app starts a new chat session with the base prompt and session data.</li> <li>The LLM generates a message, which is displayed to the therapist.</li> <li>The therapist reviews the message and decides to edit it.</li> <li>The app prompts for the category.</li> <li>The therapist provides an empty category.</li> <li>The app defaults to <code>other</code>.</li> <li>The app prompts for the feedback.</li> <li>The therapist provides empty feedback.</li> <li>The app prompts for feedback again.</li> <li>The therapist provides feedback, asking for more emojis.</li> <li>The app generates a new message.</li> <li>The app prompts for the acceptance.</li> <li>The therapist accepts the message.</li> <li>The app saves the chat history (implicit).</li> </ol> <p></p>"},{"location":"Question_2a/#handling-action-errors","title":"Handling Action Errors","text":"<p>This example shows how the chat handles wrong action inputs The user inputs invalid and empty inputs.</p> <p></p>"},{"location":"Question_2a/#enhancement-opportunities","title":"Enhancement Opportunities","text":""},{"location":"Question_2a/#asynchronous-io-optimization","title":"Asynchronous I/O Optimization","text":"<p>Issues: - File operations block the main execution thread - <code>save_chat_history()</code> is async but doesn't leverage asynchronous file I/O</p> <p>Recommendations: - Implement true asynchronous file operations with <code>aiofiles</code> - Add background saving to prevent UI lag</p> <pre><code>import aiofiles\n\nasync def save_chat_history(chat_id, chat_history):\n    \"\"\"Save chat history asynchronously without blocking.\"\"\"\n    chat_file = os.path.join(\".chats\", f\"{chat_id}.jsonl\")\n    async with aiofiles.open(chat_file, \"w\") as f:\n        for message in chat_history:\n            await f.write(json.dumps(message) + \"\\n\")\n</code></pre>"},{"location":"Question_2a/#error-handling-recovery","title":"Error Handling &amp; Recovery","text":"<p>Issues: - Basic exception handling exists but lacks granularity - No recovery mechanism for interrupted sessions</p> <p>Solution: - Implement specific exception handlers for different error types - Add session recovery mechanism</p> <pre><code>async def run_chat(session_group):\n    try:\n        # Existing code...\n    except FileNotFoundError:\n        print(\"[ERROR] Session data not found. Creating new session.\")\n        # Recovery logic\n    except NetworkError:\n        print(\"[ERROR] Connection to LLM service failed.\")\n        # Retry logic\n    except Exception as e:\n        # General fallback\n</code></pre>"},{"location":"Question_2a/#testing-evaluation-framework","title":"Testing &amp; Evaluation Framework","text":"<p>Issues: - No testing infrastructure - No metrics for message quality</p> <p>Solution: - Add unit tests for each component - Implement evaluation metrics for message quality (LLM as a Judge, interaction examples, etc.)</p>"},{"location":"Question_2a/#other-improvements","title":"Other Improvements","text":"<ul> <li>Enhanced Feedback Collection</li> <li>Model Choice Flexibility</li> <li>Load from previous chat session</li> <li>User Experience</li> <li>Extend application state graph and prompts for enhanced personalization</li> </ul>"},{"location":"Question_2a/#implementation-priorities","title":"Implementation Priorities","text":"<p>Given the current state of the application and the outlined recommendations, the following are the implementation priorities, which can have the highest impact with the least effort: - Unit tests - Enhanced error handling - Asynchronous file I/O with <code>aiofiles</code> - User experience improvements</p>"},{"location":"Question_2b/","title":"Design Document: AI-Powered PT Messaging System","text":""},{"location":"Question_2b/#problemmotivation","title":"Problem/Motivation","text":"<p>Physical Therapists (PTs) currently manually draft messages to patients following each therapy session, based on session results and predefined guidelines. This process is time-consuming and inconsistent in quality. Automating message generation will streamline PT workflows and ensure high-quality, empathetic, and engaging communication with patients.</p>"},{"location":"Question_2b/#motivation","title":"Motivation","text":"<ul> <li>Efficiency: Reduce the time PTs spend on repetitive messaging tasks.</li> <li>Consistency: Standardize messaging quality across all PTs.</li> <li>Engagement: Maintain patient motivation and adherence to therapy.</li> <li>Scalability: Support a growing number of patients without increasing PT workload.</li> </ul>"},{"location":"Question_2b/#overview-of-the-solution","title":"Overview of the Solution","text":"<p>The proposed solution is an AI-powered system that generates personalized messages for PTs to review and send. It integrates with Sword's Digital Physical Therapy platform and uses OpenAI's GPT models to create messages based on session results.</p>"},{"location":"Question_2b/#key-features","title":"Key Features","text":"<ul> <li>AI-generated messages tailored to session outcomes (<code>ok</code> or <code>nok</code>).</li> <li>Editable suggestions for PTs to customize before sending.</li> <li>Context-aware personalization using patient history.</li> <li>Compliance with tone, structure, and engagement guidelines.</li> <li>Secure, scalable deployment.</li> </ul>"},{"location":"Question_2b/#success-metrics","title":"Success Metrics","text":"Success Metric Target How to Measure PT message drafting time &gt;50% time saved per message Compare timestamps between message generation and sending before and after implementation; track average time spent in message editor PT adoption rate &gt;80% of messages accepted or minimally edited Track percentage of AI-generated messages that are sent with no edits or minimal edits (&lt;20% content change) Patient engagement 10-15% increase in session adherence Compare session completion rates before and after implementation; measure percentage of scheduled sessions completed within recommended timeframe Message rejection rate &lt;5% of messages rejected Track percentage of AI-generated messages that PTs discard and write from scratch instead Patient satisfaction &gt;85% positive feedback on communication quality Survey patients on communication quality; analyze sentiment in patient responses to PT messages Cost efficiency &lt;$0.10 average cost per message generated Calculate total API costs and infrastructure expenses divided by number of messages generated"},{"location":"Question_2b/#objectives-and-key-results-okrs","title":"Objectives and Key Results (OKRs)","text":""},{"location":"Question_2b/#objective-1-optimize-pt-workflow-efficiency","title":"Objective 1: Optimize PT Workflow Efficiency","text":"<ul> <li>KR1: Reduce message drafting time by 60% within 3 months of full deployment</li> <li>KR2: Decrease average time spent on patient communication by 40% per PT within 6 months</li> <li>KR3: Increase PT capacity (patients per PT) by 25% within 9 months</li> </ul>"},{"location":"Question_2b/#objective-2-enhance-message-quality-and-consistency","title":"Objective 2: Enhance Message Quality and Consistency","text":"<ul> <li>KR1: Achieve 85% message acceptance rate (without edits) by PTs within 4 months</li> <li>KR2: Maintain message quality score of 4.5/5 based on PT feedback</li> <li>KR3: Reduce message guideline violations by 90% compared to manual messaging</li> </ul>"},{"location":"Question_2b/#objective-3-improve-patient-engagement-and-outcomes","title":"Objective 3: Improve Patient Engagement and Outcomes","text":"<ul> <li>KR1: Increase patient session adherence by 15% within 6 months</li> <li>KR2: Improve patient satisfaction scores related to PT communication by 20%</li> <li>KR3: Reduce patient program dropout rates by 10% within 9 months</li> </ul>"},{"location":"Question_2b/#objective-4-ensure-system-reliability-and-scalability","title":"Objective 4: Ensure System Reliability and Scalability","text":"<ul> <li>KR1: Achieve 99.9% system uptime</li> <li>KR2: Maintain message generation latency under 3 seconds for 95% of requests</li> <li>KR3: Support 3x growth in message volume without performance degradation</li> </ul>"},{"location":"Question_2b/#methodology","title":"Methodology","text":""},{"location":"Question_2b/#ai-model-selection","title":"AI Model Selection","text":"<ul> <li>Primary Model: GPT-4o-mini (fast and cheap) via OpenAI's API for message generation.</li> <li>Fallback Model: GPT-4o (more powerful, but more expensive) for ensuring quality.</li> <li>LLM Workflow: Use LLM workflows (graphs) for enhanced context and quality (i.e. states and transitions).</li> <li>Contextual Retrieval: Sessions integration for efficient patient history access; relational database for patient history.</li> <li>Fine-tuning Strategy (Optional): Collect and annotate high-quality PT messages for fine-tuning; might not be reuired if prompts, context and model are powerful enough.</li> </ul>"},{"location":"Question_2b/#message-generation-pipeline","title":"Message Generation Pipeline","text":"<ol> <li>Input Preparation: Gather session results (with <code>ok</code>/<code>nok</code>), previous interactions, and patient engagement data.</li> <li>Prompt Engineering: Construct structured prompts to guide the model's output.</li> <li>Model Inference: Generate message suggestions using OpenAI's API.</li> <li>Post-Processing - Guardrails: Validate message format, remove redundancy, and apply business rules.</li> <li>UI Integration: Display the message with options to accept, edit, or reject.</li> <li>Feedback Loop: Capture PT feedback for continuous model improvement.</li> </ol>"},{"location":"Question_2b/#data-requirements","title":"Data Requirements","text":"<ul> <li>Session Data: Exercise results, completion metrics, and session classification</li> <li>Patient History: Previous messages, session patterns, reported issues</li> <li>PT Preferences: Communication style, common edits, rejection patterns</li> <li>Guideline Database: Structured repository of messaging best practices</li> </ul>"},{"location":"Question_2b/#compliance-considerations","title":"Compliance Considerations","text":"<ul> <li>Ensure patient data privacy (compliance with GDPR, healthcare data regulation (e.g. HIPAA) and others).</li> <li>Maintain a human-in-the-loop approach for PT oversight.</li> <li>Avoid AI over-reliance by allowing PTs to override AI suggestions and inplace edits.</li> <li>Regular audit of message quality and compliance with guidelines (e.g. LLM as Judge, weekly flagged interactions).</li> </ul>"},{"location":"Question_2b/#implementation-plan","title":"Implementation Plan","text":""},{"location":"Question_2b/#technical-architecture","title":"Technical Architecture","text":""},{"location":"Question_2b/#technical-stack","title":"Technical Stack","text":"<ul> <li>Backend: Python (FastAPI) for API endpoints with async support.</li> <li>Frontend: React components integrated with existing PT portal.</li> <li>Database:</li> <li>PostgreSQL for patient session history and structured data.</li> <li>Redis for caching frequent requests and rate limiting.</li> <li>Potential add-on: PGVector or Qdrant for vector embeddings and semantic search.</li> <li>Cloud Provider: AWS (Lambda, S3, DynamoDB) for scalable infrastructure.</li> <li>CI/CD: GitHub Actions for deployment automation with canary releases.</li> <li>Monitoring:</li> <li>AWS CloudWatch for infrastructure metrics.</li> <li>Datadog for application performance monitoring.</li> <li>Prometheus for custom metrics collection.</li> <li>Grafana for visualization.</li> <li>Logging: AWS CloudWatch and/or ELK stack (Elasticsearch, Logstash, Kibana) for structured logging.</li> <li>Security: AWS KMS for encryption, AWS WAF for API protection.</li> </ul>"},{"location":"Question_2b/#data-privacy-and-governance","title":"Data Privacy and Governance","text":"<ul> <li>Data Minimization: Process only necessary patient data for message generation.</li> <li>Encryption: End-to-end encryption for data in transit and at rest.</li> <li>Access Control: Role-based access with principle of least privilege.</li> <li>Audit Trail: Comprehensive logging of all data access and modifications.</li> <li>Retention Policy: Clearly defined data retention and deletion schedules.</li> <li>Data Processing Agreement: Compliance with OpenAI's terms of service.</li> </ul>"},{"location":"Question_2b/#monitoring-and-evaluation-strategy","title":"Monitoring and Evaluation Strategy","text":"<ul> <li>Model Performance:</li> <li>Message acceptance rate</li> <li>Edit distance metrics</li> <li>Sentiment analysis of PT feedback</li> <li>System Performance:</li> <li>API latency and throughput</li> <li>Error rates and types</li> <li>Resource utilization</li> <li>Business Impact:</li> <li>PT time savings</li> <li>Patient engagement metrics</li> <li>Cost per message</li> </ul>"},{"location":"Question_2b/#deployment-considerations","title":"Deployment Considerations","text":"<ul> <li>Initial rollout to a small cohort of PTs for feedback (10% of team).</li> <li>A/B testing of different prompt strategies with the pilot group.</li> <li>Gradual expansion based on performance metrics (20% &gt; 50% &gt; 100%).</li> <li>Ongoing model monitoring and improvement cycle.</li> <li>Feature flag system to quickly disable AI generation if issues arise.</li> </ul>"},{"location":"Question_2b/#main-delivery-milestones-and-timeline","title":"Main Delivery Milestones and Timeline","text":"Working Block Milestone Man/Sprint Dependencies Phase 1: Research &amp; Planning Model selection &amp; feasibility study 2 / Sprint 1 None Finalize prompt engineering strategy 2 / Sprint 2 Model selection Phase 2: Prototype Development Backend API implementation 3 / Sprint 3 Prompt engineering completed Model integration &amp; message generation 3 / Sprint 4 Backend API ready UI integration for PT feedback 2 / Sprint 5 Model integration completed Phase 3: Testing &amp; Refinement Internal testing with PTs 3 / Sprint 6 UI integration completed Iterate on model and feedback loop 3 / Sprint 7 Internal testing results Phase 4: Deployment &amp; Scaling Pilot deployment to select PTs 3 / Sprint 8 Model iteration complete Performance monitoring &amp; adjustments 2 / Sprint 9-10 Pilot deployment Full rollout 3 / Sprint 10 Performance monitoring results Phase 5: Optimization &amp; Expansion Cost optimization strategies 2 / Sprint 11 Full rollout complete Implement feedback-based fine-tuning 3 / Sprint 12 Sufficient feedback collected Analytics dashboard for PTs 2 / Sprint 13 Fine-tuning implementation"},{"location":"Question_2b/#cost-analysis","title":"Cost Analysis","text":"Component Estimated Monthly Cost Notes OpenAI API Usage $1,500 - $3,000 Based on 50,000 messages/month, varies with length AWS Infrastructure $800 - $1,200 Includes Lambda, S3, DynamoDB, CloudWatch Vector Database $300 - $500 Pinecone or similar service Monitoring &amp; Logging $200 - $400 ELK stack, Datadog Total Monthly Cost $2,800 - $5,100 Expected to decrease with optimization"},{"location":"Question_2b/#other-relevant-considerations","title":"Other Relevant Considerations","text":""},{"location":"Question_2b/#potential-shortcuts","title":"Potential Shortcuts","text":"<ul> <li>Use OpenAI's API directly before fine-tuning for faster implementation.</li> <li>Deploy a rule-based fallback system for low-confidence AI outputs.</li> <li>Leverage existing Sword infrastructure for quicker integration.</li> <li>Implement a template-based approach for common message types before full AI solution.</li> </ul>"},{"location":"Question_2b/#risks-mitigation","title":"Risks &amp; Mitigation","text":"Risk Impact Probability Mitigation Strategy AI Output Quality High Medium Continuous monitoring, human review, robust testing PT Adoption Resistance High Medium User-friendly UI, training sessions, PT champions Scalability Concerns Medium Low Load testing, optimize API calls, caching Data Privacy Breach High Low End-to-end encryption, access controls, audits OpenAI API Changes Medium Medium Model abstraction layer, fallback options Cost Overruns Medium Medium Budget monitoring, cost-saving optimizations"},{"location":"Question_2b/#future-enhancements","title":"Future Enhancements","text":"<ul> <li>Automated feedback loop to refine AI-generated messages.</li> <li>Multilingual support for global patient reach.</li> <li>Patient sentiment analysis to improve engagement strategies.</li> <li>Smart scheduling of check-ins based on adherence patterns.</li> <li>Voice-to-text integration for PTs to quickly customize messages.</li> <li>Message effectiveness analytics to correlate with patient outcomes.</li> <li>Expanded message types beyond post-session feedback.</li> </ul>"},{"location":"Question_2b/#success-criteria-for-production-release","title":"Success Criteria for Production Release","text":"<ol> <li>Message acceptance rate \u2265 80% in pilot group</li> <li>PT time savings \u2265 50% compared to manual messaging</li> <li>Zero high-severity bugs or data privacy issues</li> <li>System latency &lt; 3 seconds for 95th percentile</li> <li>Positive feedback from \u2265 75% of pilot PTs</li> </ol>"},{"location":"modules/chat/","title":"Chat","text":"<p>Chat</p>"},{"location":"modules/chat/#message.chat.llm","title":"<code>llm(messages)</code>","text":"<p>Get a chat completion from the LLM.</p>"},{"location":"modules/chat/#message.chat.llm--parameters","title":"Parameters","text":"<p>messages : list[dict[str, str]]     The messages to send to the LLM.</p>"},{"location":"modules/chat/#message.chat.llm--returns","title":"Returns","text":"<p>str     The chat completion response.</p>"},{"location":"modules/chat/#message.chat.prompt_for_acceptance","title":"<code>prompt_for_acceptance()</code>","text":"<p>Prompt user for message acceptance.</p>"},{"location":"modules/chat/#message.chat.prompt_for_acceptance--returns","title":"Returns","text":"<p>str     The response.</p>"},{"location":"modules/chat/#message.chat.prompt_for_edit_feedback","title":"<code>prompt_for_edit_feedback()</code>","text":"<p>Prompt user edit for feedback.</p>"},{"location":"modules/chat/#message.chat.prompt_for_edit_feedback--returns","title":"Returns","text":"<p>tuple[str, str]     The category and feedback.</p>"},{"location":"modules/chat/#message.chat.run_chat","title":"<code>run_chat(session_group)</code>  <code>async</code>","text":"<p>Run the chat.</p>"},{"location":"modules/chat/#message.chat.run_chat--parameters","title":"Parameters","text":"<p>session_group : str     The session group to load from file.</p>"},{"location":"modules/config/","title":"Config","text":""},{"location":"modules/data/","title":"Data","text":""},{"location":"modules/data/#message.data.get_features","title":"<code>get_features(session_group)</code>","text":"<p>Gets the features for a given session group.</p>"},{"location":"modules/data/#message.data.get_features--parameters","title":"Parameters","text":"<p>session_group : str     Session group to filter the features.</p>"},{"location":"modules/data/#message.data.get_features--returns","title":"Returns","text":"<p>dict     The features for the given session group in a dict format.</p>"},{"location":"modules/data/#message.data.open_query","title":"<code>open_query(query_filename, **kwargs)</code>","text":"<p>Opens a query file and formats it with the provided kwargs.</p>"},{"location":"modules/data/#message.data.open_query--parameters","title":"Parameters","text":"<p>query_filename : Path     Name of the query file to open.</p>"},{"location":"modules/data/#message.data.open_query--returns","title":"Returns","text":"<p>str     The query file content formatted with the provided kwargs.</p>"},{"location":"modules/data/#message.data.transform_features_py","title":"<code>transform_features_py()</code>","text":"<p>Loads the exercise results and transforms them into features.</p>"},{"location":"modules/data/#message.data.transform_features_py--returns","title":"Returns","text":"<p>pd.DataFrame     The transformed features.</p>"},{"location":"modules/data/#message.data.transform_features_sql","title":"<code>transform_features_sql()</code>","text":"<p>Loads the exercise results and transforms them into features using the features.sql query.</p>"},{"location":"modules/io/","title":"IO","text":"<p>File I/O operations.</p>"},{"location":"modules/io/#message.io.load_chat_history","title":"<code>load_chat_history(chat_id)</code>","text":"<p>Load chat history from JSONL file.</p>"},{"location":"modules/io/#message.io.load_chat_history--parameters","title":"Parameters","text":"<p>chat_id : str     The chat id.</p>"},{"location":"modules/io/#message.io.load_chat_history--returns","title":"Returns","text":"<p>list[dict[str, str]]     The chat history.</p>"},{"location":"modules/io/#message.io.load_exercise_data","title":"<code>load_exercise_data(data_dir)</code>","text":"<p>Load exercise results data from parquet file.</p>"},{"location":"modules/io/#message.io.load_exercise_data--parameters","title":"Parameters","text":"<p>data_dir : str or Path     Directory containing the exercise results data.</p>"},{"location":"modules/io/#message.io.load_exercise_data--returns","title":"Returns","text":"<p>pd.DataFrame     Raw exercise results data.</p>"},{"location":"modules/io/#message.io.load_prompts","title":"<code>load_prompts()</code>","text":"<p>Load prompts from YAML file.</p>"},{"location":"modules/io/#message.io.load_prompts--returns","title":"Returns","text":"<p>dict[str, str]     The prompts.</p>"},{"location":"modules/io/#message.io.save_chat_history","title":"<code>save_chat_history(chat_id, chat_history)</code>  <code>async</code>","text":"<p>Save chat history to JSONL file.</p>"},{"location":"modules/io/#message.io.save_chat_history--parameters","title":"Parameters","text":"<p>chat_id : str     The chat id. chat_history : list[dict[str, str]]     The chat history.</p>"},{"location":"modules/main/","title":"Main","text":""},{"location":"modules/main/#message.main.get_message","title":"<code>get_message(session_group)</code>","text":"<p>Get a message from the chat.</p>"},{"location":"modules/main/#message.main.get_message--parameters","title":"Parameters","text":"<p>session_group : str     The session group to load from file.</p>"},{"location":"modules/model/","title":"Model","text":""},{"location":"modules/model/#message.model.ChatModel","title":"<code>ChatModel</code>","text":""},{"location":"modules/model/#message.model.ChatModel.get_completion","title":"<code>get_completion(**kwargs)</code>","text":"<p>Creates a new chat completion for the provided messages and parameters.</p> <p>See https://platform.openai.com/docs/api-reference/chat/create for a list of valid parameters.</p>"},{"location":"modules/model/#message.model.ChatModel.get_completion--returns","title":"Returns","text":"<p>str     The chat completion response.</p>"},{"location":"modules/transform/","title":"Transform","text":"<p>Data Transformations</p>"},{"location":"modules/transform/#message.transform.add_reason_counts","title":"<code>add_reason_counts(df, grouped)</code>","text":"<p>Add counts for different reasons for leaving exercises.</p>"},{"location":"modules/transform/#message.transform.add_reason_counts--parameters","title":"Parameters","text":"<p>df : pd.DataFrame     Raw exercise results data. grouped : pd.DataFrame     Aggregated session data.</p>"},{"location":"modules/transform/#message.transform.add_reason_counts--returns","title":"Returns","text":"<p>pd.DataFrame     Session data with reason counts added.</p>"},{"location":"modules/transform/#message.transform.aggregate_session_data","title":"<code>aggregate_session_data(df)</code>","text":"<p>Aggregate exercise data by session group.</p>"},{"location":"modules/transform/#message.transform.aggregate_session_data--parameters","title":"Parameters","text":"<p>df : pd.DataFrame     Raw exercise results data.</p>"},{"location":"modules/transform/#message.transform.aggregate_session_data--returns","title":"Returns","text":"<p>pd.DataFrame     Data aggregated by session_group.</p>"},{"location":"modules/transform/#message.transform.calculate_performance_metrics","title":"<code>calculate_performance_metrics(grouped)</code>","text":"<p>Calculate performance metrics for each session.</p>"},{"location":"modules/transform/#message.transform.calculate_performance_metrics--parameters","title":"Parameters","text":"<p>grouped : pd.DataFrame     Aggregated session data.</p>"},{"location":"modules/transform/#message.transform.calculate_performance_metrics--returns","title":"Returns","text":"<p>pd.DataFrame     Session data with performance metrics added.</p>"},{"location":"modules/transform/#message.transform.identify_first_exercise_skipped","title":"<code>identify_first_exercise_skipped(df, grouped)</code>","text":"<p>Identify the first exercise skipped.</p>"},{"location":"modules/transform/#message.transform.identify_first_exercise_skipped--parameters","title":"Parameters","text":"<p>df : pd.DataFrame     Raw exercise results data. grouped : pd.DataFrame     Aggregated session data.</p>"},{"location":"modules/transform/#message.transform.identify_first_exercise_skipped--returns","title":"Returns","text":"<p>pd.DataFrame     Session data with first skipped exercise added.</p>"},{"location":"modules/transform/#message.transform.identify_most_incorrect_exercise","title":"<code>identify_most_incorrect_exercise(df, grouped)</code>","text":"<p>Identify exercises with problems most incorrect.</p>"},{"location":"modules/transform/#message.transform.identify_most_incorrect_exercise--parameters","title":"Parameters","text":"<p>df : pd.DataFrame     Raw exercise results data. grouped : pd.DataFrame     Aggregated session data.</p>"},{"location":"modules/transform/#message.transform.identify_most_incorrect_exercise--returns","title":"Returns","text":"<p>pd.DataFrame     Session data with problematic exercise information added.</p>"},{"location":"modules/transform/#message.transform.order_columns","title":"<code>order_columns(grouped)</code>","text":"<p>Order columns in a logical sequence.</p>"},{"location":"modules/transform/#message.transform.order_columns--parameters","title":"Parameters","text":"<p>grouped : pd.DataFrame     Session data with all features.</p>"},{"location":"modules/transform/#message.transform.order_columns--returns","title":"Returns","text":"<p>pd.DataFrame     Session data with columns in the specified order.</p>"}]}